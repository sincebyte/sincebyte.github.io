[{"authors":[],"categories":[],"content":"Ultralytics YOLOv8 和 Darknet 是与 YOLO（You Only Look Once）目标检测模型相关的两个不同实现。它的主要特点是将目标检测问题视为回归问题，直接在图像上预测边界框和类别。\nrelations YOLO（You Only Look Once）\nYOLO 是一种实时目标检测系统，由 Joseph Redmon 等人提出。它的主要特点是将目标检测问题视为回归问题，直接在图像上预测边界框和类别。\nDarknet\n开发者：Joseph Redmon。\n实现：YOLO 最早由 Joseph Redmon 在 Darknet 框架上实现。Darknet 是一个用 C 和 CUDA 编写的开源神经网络框架，专门用于目标检测。\n版本：Darknet 实现了 YOLO 的早期版本，如 YOLOv1、YOLOv2 和 YOLOv3。\nUltralytics YOLOv8\n开发者：Glenn Jocher。\n实现：Ultralytics 是一个基于 PyTorch 的开源库，最初是为了实现 YOLOv3 和 YOLOv4。后来，Ultralytics 推出了自己的版本，如 YOLOv5 和 YOLOv8。\n特点：Ultralytics 的实现更加现代化，利用 PyTorch 的灵活性和易用性，提供了更高的可扩展性和更丰富的功能，如更容易的模型训练和部署、更高的速度和精度等。\nuseage 现在使用 Ultralytics YOLOv8 是更好的选择，因为其在快速的迭代，并且有非常详细的文档。目前 yolo 模型分为：\nTrain mode: Fine-tune your model on custom or preloaded datasets. 训练调优用\nVal mode: A post-training checkpoint to validate model performance. 检测模型用\nPredict mode: Unleash the predictive power of your model on real-world data. 推理模型\nExport mode: Make your model deployment-ready in various formats. 导出模型使其能在其他硬件平台运行，或者提升模型在 CPU 下运行的效率\nTrack mode: Extend your object detection model into real-time tracking applications. 物体检测的加强版本，用于在一段视频中跟踪物体\nBenchmark mode: Analyze the speed and accuracy of your model in diverse deployment environments. 检测模型用\n想快速学习读下， https://docs.ultralytics.com/quickstart/#install-ultralytics 这篇文章即可。\n使用pip 进行依赖安装:\npip install ultralytics 第一次运行会下载预训练好的模型，我尝试过检测一段 1 分钟的视频结果失败了，应该是因为内存不够。另外 Ultralytics YOLO 利用 GPU 加速是需要使用 Nvida 的显卡才可以的。苹果电脑基本可以告吹了。\nfrom ultralytics import YOLO model = YOLO(\u0026quot;yolov8n.pt\u0026quot;) model.predict( \u0026quot;/Users/van/Desktop/yolo\u0026quot;, # \u0026quot;path/to/video.mp4\u0026quot;, # stream=True save=True, imgsz=640, conf=0.15, ) effect 训练调优 TODO\n","permalink":"/posts/yolov8/","series":[],"tags":["Ai","Python"],"title":"Yolo V8"},{"authors":[],"categories":[],"content":"h2 features are Very fast, open source, JDBC API, Embedded and server modes; in-memory databases, Browser based Console application, Small footprint: around 2.5 MB jar file size.\nDependence Add d2 dependence, You need jpa because wanna ddl-auto feature, It make project generate and apply the create tables automatically.Need mybatis dependence for sure.Fortunately they do not conflict.Note that the h2’s JDBC driver have been include in the h2 dependence.\n\u0026lt;!-- Spring Boot Starter Data JPA --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- MyBatis Starter --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- H2 Database --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.h2database\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;h2\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; Config In the application-$env.yaml the most important config is spring.datasource.Of course there need to restore programming data.When springboot starup,there generated ~/.h2/h2.mv.db, ~/.h2/h2.trace.db, ~/.h2/h2.lock.db files which are stored the ddl logs and process lock information respectively.For mybatis just use it commonly.\nspring: datasource: url: jdbc:h2:file:~/.h2/h2;AUTO_SERVER=TRUE username: sa password: ****** driverClassName: org.h2.Driver platform: h2 jpa: database-platform: org.hibernate.dialect.H2Dialect hibernate: ddl-auto: update mybatis: type-aliases-package: com.neoemacs.tool.server.po configuration: map-underscore-to-camel-case: true Each d2 database program only support a single client concurrently defaut.Use `AUTO_SERVER=TRUE` break it.\nejc Connection Use ejc connect h2 database,thing going to be done finding a h2 jdbc driver,usually you could find it under maven repository director,after that just enjoy it.\n(ejc-create-connection \u0026quot;H2\u0026quot; :classpath (file-truename \u0026quot;~/.m2/repository/com/h2database/h2/2.2.224/h2-2.2.224.jar\u0026quot;) :subprotocol \u0026quot;h2\u0026quot; :subname \u0026quot;~/.h2/h2;AUTO_SERVER=TRUE\u0026quot; :user \u0026quot;sa\u0026quot; :password \u0026quot;*****\u0026quot; :separator \u0026quot;\u0026lt;/?\\.*\u0026gt;\u0026quot;) ","permalink":"/posts/h2-usage/","series":[],"tags":["Java"],"title":"H2 Usage"},{"authors":[],"categories":[],"content":"Resumable transfer significantly improves the efficiency of file transfers,It is very efficient and convenient.Let\u0026rsquo;s try it in java\nDependencies Using commons-net 3.11.1 under spring-boot-starter-parent 3.2.6,otherwise fatal error might been occur.\n10 \u0026lt;parent\u0026gt; 11 \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; 12 \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; 13 \u0026lt;version\u0026gt;3.2.6\u0026lt;/version\u0026gt; 14 \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; 15 \u0026lt;/parent\u0026gt; 16 17 \u0026lt;dependency\u0026gt; 18 \u0026lt;groupId\u0026gt;commons-net\u0026lt;/groupId\u0026gt; 19 \u0026lt;artifactId\u0026gt;commons-net\u0026lt;/artifactId\u0026gt; 20 \u0026lt;version\u0026gt;3.11.1\u0026lt;/version\u0026gt; 21 \u0026lt;/dependency\u0026gt; FTP Client You will see the class org.apache.commons.net.ftp.FTPClient from commons-net.\n10 package com.neoemacs.video.upload.tool.server.service; 11 12 import java.io.IOException; 13 import org.apache.commons.net.ftp.FTPClient; 14 import org.springframework.beans.factory.annotation.Value; 15 import org.springframework.context.annotation.Bean; 16 import org.springframework.context.annotation.Configuration; 17 18 @Configuration 19 public class FtpClientConfiguration { 20 21 @Value(\u0026quot;${ftp.server}\u0026quot;) 22 private String ftpServer; 23 24 @Value(\u0026quot;${ftp.account}\u0026quot;) 25 private String ftpAccount; 26 27 @Value(\u0026quot;${ftp.password}\u0026quot;) 28 private String ftpPassword; 29 30 @Bean 31 public FTPClient ftpClient() { 32 FTPClient ftpClient = new FTPClient(); 33 try { 34 ftpClient.connect(ftpServer); 35 ftpClient.login(ftpAccount, ftpPassword); 36 ftpClient.enterLocalPassiveMode(); 37 ftpClient.setFileType(FTPClient.BINARY_FILE_TYPE); 38 } catch (IOException e) { 39 throw new RuntimeException(\u0026quot;Failed to create FTP client\u0026quot;, e); 40 } 41 return ftpClient; 42 } 43 } Define Interface Every ftp account have privilege to access a particular director which indeed is your client’s root. Obviously workdir is a sub director under the ftp server’s root. Here use two paramter to make the function’s purpose more clear.\n10 /** 11 * Program wil upload file on by one via breanpoint resume. 12 * 13 * e.g. uploadFile(\u0026quot;C:/Desktop/tmp\u0026quot;, \u0026quot;/record_rtp/test/20240309\u0026quot;) 14 * Files located at C:/Desktop/tmp will upload to ${workdir}/record_rtp/test/20240309/ 15 * 16 */ 17 public void uploadFile(String localFileDir, String ftpDir) throws IOException; File Offset The principle of it is query list files info from ftp server,use the size of ftp file as local file’s offset.\n10 /** 11 * get file uploaded offset from ftp server 12 */ 13 private long checkFileOffsetOnFtp(String fileName) throws IOException { 14 String remoteFile = fileName; 15 FTPFile[] files = ftpClient.listFiles(remoteFile); 16 if (files.length == 1 \u0026amp;\u0026amp; files[0].isFile()) { 17 return files[0].getSize(); 18 } 19 return 0; 20 } Start Update To start update,we need constitute a inputstream and skip it’s offset,and use a remote addr to recive stream.\n10 11 @Autowired 12 FTPClient ftpClient; 13 14 File localFile = new File(localFileDir); 15 InputStream inputStream = new FileInputStream(localFile); 16 17 String ftpFilePath = \u0026quot; \u0026quot;; 18 long offset = checkFileOffsetOnFtp(ftpFilePath); 19 inputStream.skip(offset); 20 21 ftpClient.setRestartOffset(offset); 22 boolean done = ftpClient.storeFile(ftpFilePath, inputStream); Monitor Progress The CopyStreamListener#bytesTransferred could obtains the progress of uploading.You need override the bytesTransferred , totalBytesTransferred gives the uploaded bytes but do not contains offset bytes from previously process.You could use CopyStreamListener divide by fileSize to got the uploading progress when both of their unit are bytes.\n10 ftpClient.setCopyStreamListener(new CopyStreamListener() { 11 private long megsTransferred = 0; 12 13 @Override 14 public void bytesTransferred(long totalBytesTransferred, 15 int bytesTransferred, long streamSize) { 16 long megs = totalBytesTransferred / (1024 * 1024); 17 if (megs \u0026gt; megsTransferred) { 18 megsTransferred = megs; 19 log.info(\u0026quot;==== [progress]: {}\u0026quot;, 20 (double) (totalBytesTransferred + offset) / fileSize * 100); 21 } 22 } 23 24 @Override 25 public void bytesTransferred(CopyStreamEvent event) { 26 // 此方法在复制流事件时调用 27 } 28 }); Don’t drive bytesTransferred frequency to high.Case It’s might slow down the uploading speed.\nFull Code 1 package com.minxiot.video.upload.tool.server.service; 2 3 import java.io.File; 4 import java.io.FileInputStream; 5 import java.io.IOException; 6 import java.io.InputStream; 7 import org.apache.commons.net.ftp.FTPClient; 8 import org.apache.commons.net.ftp.FTPFile; 9 import org.apache.commons.net.io.CopyStreamEvent; 10 import org.apache.commons.net.io.CopyStreamListener; 11 import org.springframework.beans.factory.annotation.Autowired; 12 import org.springframework.stereotype.Service; 13 import lombok.extern.slf4j.Slf4j; 14 15 @Slf4j 16 @Service 17 public class FileUploadService { 18 19 @Autowired 20 FTPClient ftpClient; 21 22 public void uploadFile(String localFileDir, String ftpDir) throws IOException { 23 File localDir = new File(localFileDir); 24 if (!localDir.isDirectory()) { 25 throw new IllegalArgumentException(\u0026quot;The provided path is not a directory\u0026quot;); 26 } 27 28 for (File eachLocalFile : localDir.listFiles()) { 29 if (eachLocalFile.isFile()) { 30 boolean isConnected = ftpClient.isConnected(); 31 log.info(\u0026quot;==== [ftp.isConnected]: {} \u0026quot;, isConnected); 32 log.info(\u0026quot;==== [local.fileName]: {} \u0026quot;, eachLocalFile.getAbsolutePath()); 33 String ftpFileName = ftpDir + eachLocalFile.getName(); 34 log.info(\u0026quot;==== [ftp.fileName]: {}\u0026quot;, ftpFileName); 35 if (!ftpClient.changeWorkingDirectory(ftpDir)) { 36 log.error(\u0026quot;==== [ftp.error]: {}, Cannot change to working Dir:{}\u0026quot;, 37 ftpClient.getReplyString(), ftpDir); 38 continue; 39 } 40 long offset = checkFileOffsetOnFtp(ftpFileName); 41 log.info(\u0026quot;==== [ftp.fileName.offset]: {}:{}\u0026quot;, ftpFileName, offset); 42 try (InputStream inputStream = new FileInputStream(eachLocalFile)) { 43 if (offset \u0026gt; 0) { 44 inputStream.skip(offset); 45 ftpClient.setRestartOffset(offset); 46 } 47 long fileSize = eachLocalFile.length(); 48 ftpClient.setCopyStreamListener(new CopyStreamListener() { 49 private long megsTransferred = 0; 50 51 @Override 52 public void bytesTransferred(long totalBytesTransferred, 53 int bytesTransferred, long streamSize) { 54 long megs = totalBytesTransferred / (1024 * 1024); 55 if (megs \u0026gt; megsTransferred) { 56 megsTransferred = megs; 57 log.info(\u0026quot;==== [progress]: {}\u0026quot;, 58 (double) (totalBytesTransferred + offset) / fileSize * 100); 59 } 60 } 61 62 @Override 63 public void bytesTransferred(CopyStreamEvent event) { 64 // 此方法在复制流事件时调用 65 } 66 }); 67 68 boolean done = ftpClient.storeFile(ftpFileName, inputStream); 69 if (!done) { 70 log.error(\u0026quot;==== [ftp.error]: ReplyCode:{},ReplyString:{}\u0026quot;, 71 ftpClient.getReplyCode(), ftpClient.getReplyString()); 72 } 73 } catch (IOException e) { 74 log.error(\u0026quot;==== [ftp.error]: {}\u0026quot;, e); 75 continue; 76 } 77 } 78 } 79 } 80 81 /** 82 * get file uploaded offset from ftp server 83 */ 84 private long checkFileOffsetOnFtp(String fileName) throws IOException { 85 String remoteFile = fileName; 86 FTPFile[] files = ftpClient.listFiles(remoteFile); 87 if (files.length == 1 \u0026amp;\u0026amp; files[0].isFile()) { 88 return files[0].getSize(); 89 } 90 return 0; 91 } 92 93 } ","permalink":"/posts/ftp-resume-transfer/","series":[],"tags":["Java"],"title":"Ftp Resume Transfer"},{"authors":[],"categories":[],"content":"这是使用 emacs 替代 shell 客户端的绝佳方案。在Emacs中，“tramp” 是一个系统级的文件访问工具，用于通过网络或各种连接方式导入和导出 Emacs 项目。\n简介 这是使用 emacs 替代 shell 客户端的绝佳方案。在Emacs中，“tramp” 是一个系统级的文件访问工具，用于通过网络或各种连接方式导入和导出 Emacs 项目，你可以利用 ssh 协议编辑服务器上的文件，就像在本地编辑一样，同时也可以使用 dired 进行文件拷贝，甚至使用 lsp-tramp 直接在本地对服务器的项目文件进行编码并提供代码补全功能。\n基本配置 emacs tramp 是 emacs 默认自带的功能，但是仍然有一点基础配置需要设置。首先需要安装 ssh 客户端，其次配置 ssh server 的密钥登录，这样每次使用 tramp 的时候就无需输入账号密码登录了。更简单的可以使用 ssh config 来配置 ssh 连接信息。在 `~/.ssh/config` 文件中配置。\nHOST wvp-sn ControlMaster auto ControlPath ~/.ssh/ssh-%r@%h:%p ControlPersist 10m ServerAliveInterval 60 hostname x.x.x.x Port 22 User root ForwardAgent yes ForwardX11 yes IdentityFile ~/.ssh/id_rsa 然后在 emacs 中简单配置 tramp，设置正确的文件编码，可以自动纠正 linux 文件显示乱码的问题。\n(after! tramp (setq explicit-shell-file-name \u0026quot;/bin/bash\u0026quot;)) (setq tramp-default-method \u0026quot;ssh\u0026quot;) (prefer-coding-system 'utf-8-unix) (setq-default buffer-file-coding-system 'utf-8-unix) 使用 tramp，通过 `C-x C-f` 打开文件查找输入 `/ssh:user@hostname:/path` 来打开远程文件。就可以像在编辑本地文件一样编辑远程服务器上的文件了，可以体验本地 emacs 配置的大部分功能。包括代码高量、bookmark 等等。\n文件传输 使用 dired 进行本地和服务器之间文件的互相拷贝，这真的非常方便。在 dired mode 中使用 `C` 来 copy 文件至另外的路径。当按下快捷键 `C` 以后，弹出目录，这时选择的目录可以穿越本地和服务器之间进行文件传输，甚至将远程服务器 A 上的文件通过 tramp 拷贝至远程服务器 B 也都是可行的。不过 tramp 的性能不算好，比普通的 ssh 要稍微慢一些，因此如果拷贝的文件比较大建议还是使用 scp 进行文件拷贝以免 tramp 出现超时。 也可以在 dired 利用标记功能一次性传输多个文件。\n如果 ssh 不可用，tramp 会阻塞emacs\nlsp-tramp lsp-tramp 是 lsp-mode 提供的利用 tramp 来给远程代码文件提供语言服务的功能特性。原理是通过 emacs 来远程驱动服务器上启动 lsp-server 进行代码补全，这意味着你需要在远程服务器上安装对应的 lsp-server 及启动特定 lsp-server 所需要的一切依赖。\n以 neoemacs 中使用 lsp-java 为例，首先需要安装 java17，其次需要将 jdtls 安装至 lsp-java-server-install-dir 目录，最后还需要将 lombok 和 lsp-java-format-settings-url 文件拷贝至对应的目录。需要注意的是由于是通过本地 emacs 来驱动远程服务器开启 lsp-server，因此上述文件全部需要和本地的目录一致，包括 home 目录。\n比如，本地的 home 目录为 /Users/van 则在远程服务器（wvp-test）上同样需要创建该目录，目前测试下来不能识别不同系统的家目录。在 neoemacs 中使用 maven 并没有携带指定的路径，仅需要在 shell 环境中有可执行的 `mvn` 命令即可，这需要在 .bashrc 文件中配置 PATH。\n综上，那么在 neoemacs 中使用 lsp-tramp 需要的将如下目录放置：\nssh:wvp-test:/Users/van/lsp-java ssh:wvp-test:/Users/van.doom.d/neoemacs/eclipse-codestyle.xml ssh:wvp-test:/Users/van.doom.d/neoemacs/lombok.jar ssh:wvp-test:/Users/van/soft/jdk/zulu17.40.19-ca-fx-jdk17.0.6-macosx_aarch64 ssh:wvp-test:~.m2/settings.xml ssh:wvp-test:~.bashrc 中配置 export PATH=“/ssh:wvp-test:/opt/apache-maven-3.9.7/bin:$PATH” 刚刚也提到了 tramp 由于本身是通过 ssh 协议来传输信息的，加上性能又比 ssh 要差一点，因此在使用 lsp-tramp 的时候卡顿感还是比较明显，不过还算能接受。对于比较大的项目建议不要导入项目根目录。在 lsp 初次启动的时候导入当前目录，按需导入可有效提升 lsp-tramp 的体验。\n","permalink":"/posts/emacs-tramp/","series":[],"tags":["Emacs","Tramp","Lsp Java"],"title":"Emacs Tramp"},{"authors":[],"categories":[],"content":"一直以来都使用obs进行视频录制，用了这么长时间也算是有一点心得，在这里分享一下。\n目前使用obs仍然有一些痛点，比如进行场景切换的时候很容易出现画面延迟，基于这种情况我必须要使用obs的监视器确认画面是否延迟，这会使得在视频录制时有一些分心，还有就是录制透明通道的视频文件过于庞大。\n视频设置 由于我使用sony a7c录制工作台作为视频的背景，然后再使用obs录制 emacs or browser 最后再进行合成视频。因此首先我们需要录像一个背景透明的视频。\n在obs中视频的基础设置包括在 设置-\u0026gt;视频。设置基础画布分辨率，如果想录制高清的视频，使用好的显示器是必须的。\n严格来说，4K 的标准分辨率是 4096x2160 像素，而 2160p 则是 3840x2160 像素的分辨率。\nU27v5c显示器: 3840x2160 分辨率\nmacos 显示器: 3024x2160 分辨率\n输出分辨率: 基础分辨率保持不变。\n常用帧率：设置为29.97\n在设置-\u0026gt;输出-\u0026gt;录像内设置录制带透明通道的视频：\n视频编码器：png -PNG(Portable Network Graphics)image\n容器格式：mov\n视频码率：12000 Kbps\n关键帧间隔(帧)：30\n音频码率：160 Kbps\n音频编码器：acc-ACC(ADvanced Audio Coding)\n音轨：勾选1（这里注意，在场景和源中输出音轨中要匹配）\n快捷键 可以设置快捷键来进行场景切换：\n设置-\u0026gt;快捷键，常用的快捷键一般包括录制控制、场景切换\n开始录制： ⌘⇞\n停止录制： ⌘⇟\n切换场景1： F8\n切换场景2： F9\n注意：快捷键需要避开系统快捷键，以免铵键时发生冲突\n创建场景 接下来创建2个场景，分别录制Emacs与chrome浏览器。以使得录制时可以进行画面切换 创建场景后在来源里添加窗口采集，选择显示名称为空的窗口就可以添加emacs窗口的画面了。\nchrome也是一样，不过由于obs通过窗口的标题来识别窗口，因此重新打开obs的时候需要将浏览器的标题设置为与添加至来源时的标题相同才能被obs识别，好的办法是使用浏览器的新标签页来做为识别页面。\n声音录制 声音使用loopback进行多音源合成，这里就不展开介绍了。\n在obs里面仍然是在来源里面添加“音频输入采集”，然后选择loopback的虚拟设备(devices)就可以了\n混音器里面此时就会增加一个音源\n避免重音：混音器-\u0026gt;高级音频设置-\u0026gt;音频监听-\u0026gt;关闭监听\n输出音轨：这里就要和录制时的音轨一致声音才会被录制下来\n画面监视器 在停靠窗口中关闭场景、来源、混音器、转场动画、控制按钮、统计，可以得到一个干净的监视器\n文件大小 经测试两个显示器录制的文件大小是一样的。\n显示器 编码器 文件大小 U27v5c png 1.17GB/min macbook png 1.17GB/min ","permalink":"/posts/obs-usage/","series":[],"tags":["Obs","Video"],"title":"Obs Usage"},{"authors":[],"categories":[],"content":"Docker Compose 是一个用于定义和运行多个 Docker 容器应用程序的工具。它通过一个简单的 YAML 文件来配置应用程序的服务、网络、卷等方面，然后使用单个命令启动、停止和管理整个应用程序的容器。\nIntroduction Docker 官方还维护了一个很方便的工具 docker compose，使用macos 安装 docker desktop 自带docker compose，其他情况需要单独安装。\nDocker Compose 是一个用于定义和运行多个 Docker 容器应用程序的工具。它通过一个简单的 YAML 文件来配置应用程序的服务、网络、卷等方面，然后使用单个命令启动、停止和管理整个应用程序的容器。Docker Compose 简化了多个容器之间的交互和管理，提供了一种简便的方式来部署和管理基于容器的应用程序。\nProcess docker-comose.yml 创建一个docker-compose.yml文件，用来定义容器及设置参数。\nTable 1: docker-compose 参数文件说明 config describe services 容器列表 \\_zlm 容器名称，实际镜像名称会加上文件名 build 镜像的构建目录，支持相对路径（相对docker-compose.yml) build.dockerfile 镜像的dockerfile文件 command 容器的启动命令 ports 设置暴露端口，通过 ${STREAM_PORT} 引用环境变量 volumes 设置硬盘挂载 ,前面是容器内的目录，后面是宿主机的目录 extra_hosts 设置host environment 设置环境变量，适合环境变量较少的情况 env_file.env 引入外部环境变量文件，适合环境变量较多情况 services: zlm: container_name: zlm build: context: ./zlm dockerfile: Dockerfile command: [\u0026quot;/opt/media/MediaServer\u0026quot;, \u0026quot;-m\u0026quot;, \u0026quot;3\u0026quot;, \u0026quot;-c\u0026quot;,\u0026quot;/opt/media/config/config.ini\u0026quot;] restart: always ports: - \u0026quot;${STREAM_PORT}:${STREAM_PORT}/udp\u0026quot; extra_hosts: - \u0026quot;stream-test.wvp.com:127.0.0.1\u0026quot; env_file: - .env wvp: container_name: wvp build: context: ./wvp dockerfile: Dockerfile restart: always ports: - \u0026quot;5060:5060\u0026quot; volumes: - ./node_modules:/opt/wvp/node_modules environment: - TZ=\u0026quot;Asia/Shanghai\u0026quot; extra_hosts: - \u0026quot;stream-test.wvp.com:127.0.0.1\u0026quot; catalog 整个 docker compose 的项目目录\n. ├── docker-compose.yml ├── .env ├── wvp │ ├── Dockerfile │ └── config │ ├── application.yml │ └── run-wvp.sh └── zlm ├── Dockerfile └── config ├── config.ini ├── default.pem └── run-zlm.sh env_file.env .env 环境变量文件，支持在不同的环境中可引入不同的环境变量参数，可以在这里配置 Key/Value 键值对，方便在docker compose中引用。\n幸运的是 springboot 项目也支持通过和 docker comopse 相同的方式引入环境变量，则数据库连接、账号、密码等信息均可以通过这种方式来进行管理。\nTZ=Asia/Shanghai STREAM_PORT=30000-30050 spring: application: name: wvp redis: host: ${REDIS_HOST:127.0.0.1} port: ${REDIS_PORT} database: ${REDIS_DB} password: ${REDIS_PWD} timeout: 10000 Dockerfile 在dockerfile中使用非交互式安装，通过设置 `DEBIAN_FRONTEND=noninteractive`，可以将 Debian 系统的安装程序设置为非交互式模式，这样在安装软件包时不会出现任何交互式提示或确认，所有的安装选择都会使用默认设置。\nFROM ubuntu:20.04 ENV LC_ALL zh_CN.UTF-8 RUN export DEBIAN_FRONTEND=noninteractive \u0026amp;\u0026amp; \\ apt-get update \u0026amp;\u0026amp; \\ apt-get install -y --no-install-recommends curl \u0026amp;\u0026amp; \\ curl -fsSLk https://deb.nodesource.com/setup_20.x -o nodesource_setup.sh \u0026amp;\u0026amp; \\ chmod +x nodesource_setup.sh \u0026amp;\u0026amp; ./nodesource_setup.sh --yes \u0026amp;\u0026amp; rm nodesource_setup.sh \u0026amp;\u0026amp; \\ apt update \u0026amp;\u0026amp; \\ apt-get install -y --no-install-recommends openjdk-11-jre git nodejs maven build-essential \\ cmake ca-certificates openssl \u0026amp;\u0026amp; \\ npm cache clean --force \u0026amp;\u0026amp; npm install vite -g \u0026amp;\u0026amp; \\ apt-get autoremove -y \u0026amp;\u0026amp; \\ apt-get clean -y \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/*dic CMD [\u0026quot;sh\u0026quot;, \u0026quot;/opt/wvp/config/run-wvp.sh\u0026quot;] run script #!/bin/bash cd /home || exit echo \u0026quot;clone start\u0026quot; git clone -b release1.6 http://vanniuner:password@github.com/wvp-gb28181-pro/wvp-gb28181-pro.git echo \u0026quot;clone done\u0026quot; git log -1 echo \u0026quot;node version:\u0026quot; $(node -v) echo \u0026quot;build web_src\u0026quot; cd wvp-gb28181-pro/web_src || exit npm config set prefix /opt/wvp/node_modules # uncomment below if new pacakge need echo \u0026quot;web_src install start\u0026quot; npm install --registry=https://mirrors.tencent.com/npm/ --legacy-peer-deps cp -rf ./node_modules /opt/wvp echo \u0026quot;web_src install done\u0026quot; echo \u0026quot;web_src run build start\u0026quot; npm run build echo \u0026quot;web_src run build done\u0026quot; cd /home/wvp-gb28181-pro || exit mvn clean package -Dmaven.test.skip=true -s settings.xml -Dmaven.repo.local=/opt/wvp/repo cp /home/wvp-gb28181-pro/target/*.jar /opt/wvp/ cd /opt/wvp || exit java -jar *.jar --spring.config.location=/opt/wvp/config/application.yml command build the docker image\ndocker compose build restart docker compose containers and output a particular containers log\ndocker compose down \u0026amp;\u0026amp; docker compose up -d \u0026amp;\u0026amp; docker compose logs -f -n100 wvp ","permalink":"/posts/docker-compose-usage/","series":[],"tags":["Docker"],"title":"Docker Compose Usage"},{"authors":[],"categories":[],"content":"org mode 可以记录您在特定任务中花费了多长时间，最终通过统计结果来进行分析回顾，对于时间管理有需求的专业人士这是很棒的功能。\ncontent 分项计时 org mode 可以记录您在特定任务中花费了多长时间，这主要通过两个函数来实现 `org-clock-in` 、 `org-clock-out`。 在指定大纲之下执行 `org-clock-in` 将开始这个分项的计时。如果您使用 doom emacs modeline ，可以看到统计到时间的 segment。然后在同样的大纲分项下执行 `org-clock-out`， 将结束这个分项的计时。org mode 通过在分项下插入了特定的代码片段，并写入开始和结束时间来记录任务的实际花费。如果发现时间记录有误，也可以通过手动调整开始和结束时间来修订。\n* org clock task :LOGBOOK: CLOCK: [2024-04-06 Sat 12:31]--[2024-04-06 Sat 12:32] =\u0026gt; 0:01 :END: emacs 函数 快捷键 意义 org-clock-in SPC m c i 开始分项的计时 org-clock-in SPC m c o 结束分项的计时 org-clock-report SPC m c R 统计分析 统计分析 统计好时间以后，使用 org-clock-report 对项目、分项进行统计分析。\n#+BEGIN: clocktable :scope subtree :maxlevel 2 :compact t #+CAPTION: Clock summary at [2024-04-06 Sat 18:13] | Headline | Time | |--------------+--------| | *Total time* | *0:02* | |--------------+--------| | 抓包 | 0:02 | | \\_ 抓包 | 0:01 | #+END: Table 1: org-clock-report 参数意义 参数 可选值 意义 scope file、subtree 当前文件范围 scope (\u0026ldquo;a.org\u0026rdquo; \u0026ldquo;b.org\u0026rdquo;) 多个文件范围 maxlevel \u0026gt;0 统计粒度 compact nil or t 紧凑模式 tags nil or t 导出标签 block today yesterday thisweek thismonth thisyear 按时间区间筛选 当统计的文件数量过多时可通过简单的elisp代码来扩展scope, 如下代码展示了如何将统计范围指定到 ~/Desktop/ 目录下的所有org文件\n#+BEGIN: clocktable :scope (lambda () (directory-files-recursively \u0026quot;~/Desktop/\u0026quot; \u0026quot;.org\u0026quot;)) ","permalink":"/posts/org-clock/","series":[],"tags":["Emacs","Org-Mode"],"title":"Org Clock"},{"authors":[],"categories":[],"content":"I don’t use python much, but I still record the useful information.\npyenv Use pyenv download a python version and shift to that particular version.\ninstall pyenv\n1 brew install pyenv set on fish\n1 set PYENV_ROOT $HOME/.pyenv 2 set -x PATH $PYENV_ROOT/shims $PYENV_ROOT/bin $PATH 3 pyenv rehash TODO: there lack of a settlment about bash\npyenv usage\nUse pyenv global shift to a particular verison , will effect the python and pip lib version.\n1 pyenv install 3.11 2 pyenv global 3.11 3 python -V 4 pip -V emacs compile emacs lsp langrage\nM-x lsp-install-server pyright\ncompile\nUse compile-command binding to SPC c c for custom the compile command.\n# -*- compile-command: \u0026quot;python test.py\u0026quot;; -*- \u0026quot;\u0026quot;\u0026quot;this is the doc.\u0026quot;\u0026quot;\u0026quot; thisdict = { \u0026quot;brand\u0026quot;: \u0026quot;Ford\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Mustang\u0026quot;, \u0026quot;year\u0026quot;: 1964 } print(thisdict) manim Manim can easily draw animated videos.\nTo become familiar with its use you may need to study for 1 day.\nI think there may be a good start https://www.youtube.com/watch?v=q34jwI4zcMY.\nOfficial documentation：https://docs.manim.community/en/stable/\n# -*- compile-command: \u0026quot;manim /Users/van/Desktop/target/scene.py UnwriteReverseTrue -pqh\u0026quot;; -*- from manim import * # manim scene.py UnwriteReverseTrue -pqh # manim scene.py UnwriteReverseTrue --format mov -qk -t class UnwriteReverseTrue(Scene): def construct(self): # emacs = ImageMobject(\u0026quot;Blackvariant-Button-Ui-Requests-6-Emacs.1024.png\u0026quot;) emacs = SVGMobject(\u0026quot;GNU_Emacs-Logo.wine.svg\u0026quot;, stroke_color=\u0026quot;#6247a1\u0026quot;) emacs.height = 2 emacs.scale(0.4) color = iter([\u0026quot;#42208c\u0026quot;, \u0026quot;#6247a1\u0026quot;, \u0026quot;white\u0026quot;]) for layer in emacs: temp = next(color) print(temp) layer.set_color(temp) if temp == \u0026quot;#6247a1\u0026quot;: print(\u0026quot;sacle layer\u0026quot;) layer.scale(0.8) self.add(emacs) emacs.shift(LEFT * 4) g = MarkupText( '\u0026lt;b\u0026gt;\u0026lt;span foreground=\u0026quot;#d956ff\u0026quot; size=\u0026quot;x-large\u0026quot; style=\u0026quot;oblique\u0026quot;\u0026gt;G\u0026lt;/span\u0026gt;\u0026lt;/b\u0026gt;', font=\u0026quot;Optima\u0026quot;, ) self.add(g) g.shift(LEFT * 3) o = MarkupText( '\u0026lt;b\u0026gt;\u0026lt;span foreground=\u0026quot;#fa9175\u0026quot; size=\u0026quot;x-large\u0026quot; style=\u0026quot;oblique\u0026quot;\u0026gt;O\u0026lt;/span\u0026gt;\u0026lt;/b\u0026gt;', font=\u0026quot;Optima\u0026quot;, ) self.add(o) o.move_to(LEFT * 2.4) left_l = MarkupText( '\u0026lt;b\u0026gt;\u0026lt;span foreground=\u0026quot;#d956ff\u0026quot; size=\u0026quot;x-large\u0026quot;\u0026gt;L\u0026lt;/span\u0026gt;\u0026lt;/b\u0026gt;', font=\u0026quot;Mshtakan\u0026quot;, ) self.add(left_l) left_l.move_to(UP * 2 + LEFT * 1.8) left_e = MarkupText( '\u0026lt;b\u0026gt;\u0026lt;span foreground=\u0026quot;#d956ff\u0026quot; size=\u0026quot;x-large\u0026quot;\u0026gt;E\u0026lt;/span\u0026gt;\u0026lt;/b\u0026gt;', font=\u0026quot;Mshtakan\u0026quot;, ) self.add(left_e) left_e.move_to(UP * 2.5 + LEFT * 1.2) m = MarkupText( '\u0026lt;b\u0026gt;\u0026lt;span foreground=\u0026quot;#fe86fe\u0026quot; size=\u0026quot;x-large\u0026quot;\u0026gt;M\u0026lt;/span\u0026gt;\u0026lt;/b\u0026gt;', font=\u0026quot;BM Hanna Air\u0026quot;, ) self.add(m) m.move_to(UP * 3 + LEFT * 0.65) g2 = MarkupText( '\u0026lt;b\u0026gt;\u0026lt;span foreground=\u0026quot;#fa9175\u0026quot; size=\u0026quot;x-large\u0026quot;\u0026gt;G\u0026lt;/span\u0026gt;\u0026lt;/b\u0026gt;', font=\u0026quot;Mshtakan\u0026quot; ) self.add(g2) g2.move_to(RIGHT * 3) e1 = MarkupText( '\u0026lt;b\u0026gt;\u0026lt;span foreground=\u0026quot;#fa9175\u0026quot; size=\u0026quot;x-large\u0026quot;\u0026gt;E\u0026lt;/span\u0026gt;\u0026lt;/b\u0026gt;', font=\u0026quot;Mshtakan\u0026quot; ) self.add(e1) e1.move_to(RIGHT * 3.5) e2 = MarkupText( '\u0026lt;b\u0026gt;\u0026lt;span foreground=\u0026quot;#fa9175\u0026quot; size=\u0026quot;x-large\u0026quot;\u0026gt;E\u0026lt;/span\u0026gt;\u0026lt;/b\u0026gt;', font=\u0026quot;Mshtakan\u0026quot; ) self.add(e1) e2.move_to(RIGHT * 4) k = MarkupText( '\u0026lt;b\u0026gt;\u0026lt;span foreground=\u0026quot;#fe86fe\u0026quot; size=\u0026quot;x-large\u0026quot;\u0026gt;K\u0026lt;/span\u0026gt;\u0026lt;/b\u0026gt;', font=\u0026quot;Gurmukhi MN\u0026quot;, ) self.add(k) k.move_to(RIGHT * 4) onTincidunt = MarkupText( '\u0026lt;b\u0026gt;\u0026lt;span foreground=\u0026quot;#d956ff\u0026quot; size=\u0026quot;large\u0026quot;\u0026gt;ON TINCIDUNT\u0026lt;/span\u0026gt;\u0026lt;/b\u0026gt;', font=\u0026quot;Optima\u0026quot;, ) self.add(onTincidunt) onTincidunt.move_to(DOWN * 5, RIGHT * 4) g2.shift(RIGHT * 1) e1.shift(RIGHT * 2) e2.shift(RIGHT * 3) k.shift(RIGHT * 3) # let font to init position leftValueInit = 0.1 self.play( Circumscribe(emacs, Circle, color=\u0026quot;#0984e3\u0026quot;, buff=-1, fade_out=True), left_l.animate.move_to(LEFT * 1.8), left_e.animate.move_to(LEFT * 1.2), m.animate.move_to(LEFT * 0.6), g2.animate.move_to(RIGHT * leftValueInit), e1.animate.move_to(RIGHT * (leftValueInit + 0.6)), e2.animate.move_to(RIGHT * (leftValueInit + 1.2)), k.animate.move_to(RIGHT * (leftValueInit + 1.75)), onTincidunt.animate.move_to(DOWN * 0.8 + RIGHT * 1.5), lag_ratio=0.5, run_time=3, ) # right out leftvalue = 1 self.play( emacs.animate.move_to(RIGHT * 0.2), g2.animate.move_to(RIGHT * leftvalue), e1.animate.move_to(RIGHT * (leftvalue + 0.6)), e2.animate.move_to(RIGHT * (leftvalue + 1.2)), k.animate.move_to(RIGHT * (leftvalue + 1.75)), lag_ratio=0.5, run_time=0.4, ) # right int leftvalue = 0.4 self.play( emacs.animate.move_to(DOWN * 0.2 + LEFT * 0.1).scale(0.25), g2.animate.move_to(RIGHT * leftvalue), e1.animate.move_to(RIGHT * (leftvalue + 0.6)), e2.animate.move_to(RIGHT * (leftvalue + 1.2)), k.animate.move_to(RIGHT * (leftvalue + 1.75)), run_time=0.8, ) self.wait(10) ","permalink":"/posts/python-basic-useage-inneoemacs/","series":[],"tags":["Python","Emacs"],"title":"Python Basic Useage Inneoemacs"},{"authors":[],"categories":[],"content":"autohotkey 在 windows 上改键的神器. 借此可以实现在 macos 下与 karabiner-Elements 同样的效果.\nkey binding shorcut effect F7 stop autohotkey effect win + k popup emacs win + r popup edge win + c copy win + v paste win + x cut win + z undo win + y redo casplock with single escape casplock with otherkeys ctrl with other keys config code #k:: WinTitle := \u0026quot;ahk_exe emacs.exe\u0026quot; WinGet WinState, MinMax, %WinTitle% ; retrieve minimized/maximized state if (WinState = -1) ; minimized WinRestore, %WinTitle% else ; not minimized WinMinimize, %WinTitle% Return !k:: WinTitle := \u0026quot;ahk_exe emacs.exe\u0026quot; WinGet WinState, MinMax, %WinTitle% ; retrieve minimized/maximized state if (WinState = -1) ; minimized WinRestore, %WinTitle% else ; not minimized WinMinimize, %WinTitle% Return #r:: WinTitle := \u0026quot;ahk_class Chrome_WidgetWin_1\u0026quot; WinGet WinState, MinMax, %WinTitle% ; retrieve minimized/maximized state if (WinState = -1) ; minimized WinRestore, %WinTitle% else ; not minimized WinMinimize, %WinTitle% Return !r:: WinTitle := \u0026quot;ahk_class Chrome_WidgetWin_1\u0026quot; WinGet WinState, MinMax, %WinTitle% ; retrieve minimized/maximized state if (WinState = -1) ; minimized WinRestore, %WinTitle% else ; not minimized WinMinimize, %WinTitle% Return #;:: WinTitle := \u0026quot;ahk_exe WXWork.exe\u0026quot; WinGet WinState, MinMax, %WinTitle% ; retrieve minimized/maximized state if (WinState = -1) ; minimized WinRestore, %WinTitle% else ; not minimized WinMinimize, %WinTitle% Return #c:: send ^c Return #v:: send ^v Return #x:: send ^x Return #z:: send ^z Return #y:: send ^y Return !c:: send ^c Return !v:: send ^v Return !x:: send ^x Return !z:: send ^z Return !y:: send ^y Return !d:: send #d Return F7:: Suspend, Off Pause, Off, 1 If (toggle := !toggle) Suspend, On Pause, On, 1 Return g_LastCtrlKeyDownTime := 0 g_AbortSendEsc := false g_ControlRepeatDetected := false *CapsLock:: if (g_ControlRepeatDetected) { return } send,{Ctrl down} g_LastCtrlKeyDownTime := A_TickCount g_AbortSendEsc := false g_ControlRepeatDetected := true return *CapsLock Up:: send,{Ctrl up} g_ControlRepeatDetected := false if (g_AbortSendEsc) { return } current_time := A_TickCount time_elapsed := current_time - g_LastCtrlKeyDownTime if (time_elapsed \u0026lt;= 250) { SendInput {Esc} } return question There always have one question confuse me is I wanna binding a shorcut only on a particular application. I tried some of the solution support by the autohotkey offically, but it does not work well. I will keep looking for the solution.\n","permalink":"/posts/windows-autohotkey-setting/","series":[],"tags":["Emacs","Windows"],"title":"Windows Autohotkey Setting"},{"authors":[],"categories":[],"content":"项目初期如何快速搭建符合规范、便于定制的项目结构, 相信这是大家一直在追求的. 所幸 Maven 提供了 archetypes 插件可满足这一诉求.\nprinciple 通过下图我们可以知道, 要制作一个项目骨架大致需要以下几个步骤\n创建一个example工程, 此 example 工程 包含了架构师对框架的设计, 如 module 划分、依赖关系、包结构设计等等 使用 Archetypes 插件对 example 工程进行配置并打包, 完成后骨架工程的代码被放在 example/target 目录之下 在编译完成的骨架工程目录下执行 mvn install/mvn deploy 对骨架工程进行发布 在另外一个目录使用 archetype:generate 命令从骨架工程生成项目 create from project 对 example 工程的创建. 需要注意的是 maven 各模块内的包名需要定义一个通用的开头, 例如 com.pkg.\n在最外层 pom 目录下增加 archetype 的配置文件 archetype.properties. excludePatterns 表示打包至 target 目录下的文件.\n1 excludePatterns=.idea/,.settings/,.classpath,.project 2 gitignore=.gitignore 使用 archetype:create-from-project 创建 archetype 项目, 并指定配置文件及通用包名\n然后使用 mvn clean deploy 对 target 目录下的 archetype 项目进行发布\n1 #!/bin/bash 2 set -e 3 echo \u0026quot;====longda-archetype build successfully\u0026quot; 4 mvn clean archetype:create-from-project -Darchetype.properties=archetype.properties \\ 5 -Darchetype.filteredExtentions=* -DpackageName=com.pkg 6 echo \u0026quot;====longda.archetype build successfully\u0026quot; 7 mvn clean deploy javadoc:jar source:jar -f target/generated-sources/archetype/pom.xml 8 echo \u0026quot;====longda.archetype install successfully\u0026quot; generate project 运行下面的命令来生成项目骨架\n1 mvn archetype:generate \\ 2 -DarchetypeGroupId=com.archetype \\ 3 -DarchetypeArtifactId=archetype-archetype \\ 4 -DarchetypeVersion=0.1.0-SNAPSHOT \\ 5 -DinteractiveMode=false \\ 6 -DgroupId=com.center.crm \\ 7 -DartifactId=center-crm \\ 8 -Dversion=3.10.0-CD-LD-SNAPSHOT \\ 9 -Dpackage=com.center.crm 这个命令所构建的项目是 parent 的一个子模块。\nartifactId 这也是目标项目的文件夹名称\nTable 1: 命令参数注释说明 参数名 含义说明 值说明 archetypeGroupId 骨架项目的GroupId 固定值 com.archetype archetypeArtifactId 骨架项目的ArtifactId 固定值 archetype-archetype archetypeVersion 骨架项目的Version 最新版本参考 Update interactiveMode 命令行交互模式 固定值 false groupId 目标项目的 GroupId 格式 com.center.%appName% artifactId 目标项目的 ArtifactId 格式 center-%appName% version 目标项目的 Version 固定值 3.10.0-CD-LD-SNAPSHOT package 目标项目的包路径 格式 com.center.%appName% 项目创建好，并且成功上传至 gitlab 代码仓库以后\n需要将项目作为一个 submodule 添加至 parent 的根目录下\n并且需要在 parent/pom.xml 的 modules 节点处增加此项目，以做归档\n","permalink":"/posts/maven-%E9%A1%B9%E7%9B%AE%E9%AA%A8%E6%9E%B6/","series":[],"tags":["Maven","Java"],"title":"Maven 项目骨架"},{"authors":[],"categories":[],"content":"在Neo Emacs中制作表格和绘图可极大激发我们的生产力, 除了使用PlantUML、D2、dot graphviz等绘图工具外, 可以将 org table 与 gnuplot 结合形成强大的绘制统计报表的需求, 进行各类汇总报告分析.\nOrg Table org table 支持进行列运算通过 #+TBLFM 标签编写表达式可对列进行多次的操作.\nTable 1: 符号及意义 符号 意义 开始值 @ 指定行 1 .. @3.. 表示从第3行之后 \u0026#xa0; $ 指定列 1 :: 分隔符多个执行的表达式 \u0026#xa0; @# 行号 1 分析下面这行表达式的意义, 等号左边表示要赋值的表格的范围, @3..$1 表示赋值范围从第3行第1列至最后一行第1列.\n等号右边是一个运算表达式, @2$1 表示初始值为第2行第1列 . @# 表示当前行号.\n由于我们是从第3行开始赋值, 因此表达式首次执行该值为3, 最后进行了减 2, 则 @3$1=2019+3-2.\n通过分析可知道,这个表达式其实是让第一列从第2行开始向后自增.\n年度 平台A 平台B 2019 37 33 2020 75 25 2021 155 255 2022 268 398 2023 427 520 2024 640 740 2025 922 1022 2026 1271 1369 #+TBLFM: @3..$1=@2$1+@#-2 Gnuplot Histograms Gnuplot comes with a large collection of demonstration plots. You can step through these interactively by typing the command below in gnuplot’s demo/ directory — it should be part of your installation, otherwise get it from the source code archive or file-by-file from the git repository.\nTable 2: gnuplot 参数 command 说明 值域 data 选择数据表格 表格设置: #+TBLNAME: data-bb3 exports 导出方式 code、results、both、none set title 设置标题 显示在图片表格上方 set boxwidth 设置柱宽 建议: 0-1之间的小数 set yrange 设置Y轴范围, 改boxwidth生效 [0:1600] data u 每一行设置表示一个直方图 - plot 2:xticlabel(1) 设置Y:X轴对应列 2表示Y轴高度列, 1表示用第1列作为X轴显示内容 plot title 设置图例名 \u0026ldquo;legend\u0026rdquo; with boxes using 0:2:2 设置柱标记数 0:2:2, 最后一个2表示用哪列数据 using offset 设置柱标记数位置 0,0.5 分别表示x和y方向的偏移量 with 图表类型 histograms、points、linepoints style 图表样式 linecolor、pointtype、pointsize set title \u0026quot;2019-2026 Computing power prediction\u0026quot; set grid set autoscale set boxwidth 0.9 set yrange [0:1800] set style histogram gap 1 set style fill solid 1.0 border plot data u 2:xticlabel(1) title \u0026quot;平台A\u0026quot; with histograms linecolor rgb \u0026quot;#3498DB\u0026quot;, \\ '' using 0:2:2 with labels center offset -1.5,0.5 notitle ,\\ data u 3:xticlabel(1) title \u0026quot;平台B\u0026quot; with histograms linecolor rgb \u0026quot;#1ABC9C\u0026quot;, \\ '' using 0:3:3 with labels center offset 1,0.5 notitle ,\\ data u 2:xticlabel(1) title \u0026quot;平台A\u0026quot; with linespoints pointtype 7 pointsize 0.6 linecolor 1, \\ data u 3:xticlabel(1) title \u0026quot;平台B\u0026quot; with linespoints pointtype 7 pointsize 0.6 linecolor 2 set title \u0026quot;2019-2026 computing power prediction line\u0026quot; set grid set autoscale set boxwidth 0.9 set yrange [0:1600] set style fill solid 1.0 border plot data u 2:xticlabel(1) title \u0026quot;平台A\u0026quot; with line, \\ '' using 0:2:2 with labels center offset -1,0.5 notitle ,\\ data u 3:xticlabel(1) title \u0026quot;平台B\u0026quot; with line, \\ '' using 0:3:3 with labels center offset 1,0.5 notitle ","permalink":"/posts/%E5%9C%A8neo-emacs%E4%B8%AD%E5%88%B6%E4%BD%9C%E8%A1%A8%E6%A0%BC%E5%92%8C%E7%BB%98%E5%9B%BE/","series":[],"tags":["Org","Emacs","Gnuplot"],"title":"在neo Emacs中制作表格和绘图"},{"authors":[],"categories":[],"content":"clickhouse 可用于联机分析OLAP的列式数据库管理系统. 定位与OLAP离线数据处理,相比于OLTP在线事务处理,clickhouse更关注于海量数据的计算分析, 关注的是数据的吞吐、查询速度、计算性能等指标.\n简介 而对于数据频繁的变更不擅长. 所以clickhouse通常用来构建后端的时实数仓.\n所谓列式存储是指,与Mysql这种行式存储的不同,数据是按列来集中存储的.因此在我们进行有限的字段数据分析的时候会读更少的文件,因此减少了很多的IO读取工作量.\n对clickhouse最耗的是CPU, 因此clickhouse的部署需要独立的部署 .\nOLAP\nOLAP scenarios require real-time responses on top of large datasets for complex analytical queries with the following characteristics:\nDatasets can be massive - billions or trillions of rows Data is organized in tables that contain many columns Only a few columns are selected to answer any particular query Results must be returned in milliseconds or seconds 安装 sudo apt-get install -y clickhouse-server clickhouse-client sudo service clickhouse-server start clickhouse-client # or \u0026quot;clickhouse-client --password\u0026quot; if you've set up a password. show databases; # a attempt for clickhouse show tables; # a attempt for clickhouse 表引擎 表引擎是Clickhouse的一大特色\n建表时必须指定, 决定了如何存储表, 从哪里读取数据. 支持哪些查询,以及如何支持, 有些语法在特定的表引擎才能使用. 是否可以多线程请求 数据复制参数 引擎 说明 TinyLog 不支持索引、没有并发. 一般保存小量的数据 Memory 数据以未压缩的原始形式直接保存在内存中, 重启数据会丢失, 简单查询下性能高, 不建议生产使用 MergeTree 每次插入时, 引擎进行一次合并再存入数据库, 合并树引擎是最强大的, 而且它有很多子分类 RepalingMergeTree 最大程度保证数据最终一致性 数据同步 期初数据使用全量同步的方式同步至clickhouse 增量数据使用kettle或者logstash定时抽取至clickhouse 实现\njdbc(datasource, schema, table) - returns table that is connected via JDBC driver.\nThis table function requires separate clickhouse-jdbc-bridge program to be running. It supports Nullable types (based on DDL of remote table that is queried).\nclickhouse sql statment\ninsert into report.target_table select * from jdbc('jdbc:mysql://localhost:3306/?user=root\u0026amp;password=root', `select * from origin_table where update_time\u0026gt;@1`) clickhouse execution\nclickhouse-client --user ${ck_user} --password ${ck_pass} --port ${ck_port} \\ -d report --multiquery \u0026lt; ../sql/${sql_name} 代码集成 clickhouse支持JDBC驱动, 因此集成click就如同集成一个数据源一样简单\nJDBC驱动\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.clickhouse\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;clickhouse-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.4.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 多数据源\n配置clickhouse多数据源配置类\npackage com.cloud.center.b3expand.config; import javax.sql.DataSource; import com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean; import com.zaxxer.hikari.HikariDataSource; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.annotation.MapperScan; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.boot.autoconfigure.jdbc.DataSourceProperties; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.support.PathMatchingResourcePatternResolver; /** * @author liu.zijie * @since 2023-09-12 **/ @Configuration @MapperScan(basePackages = \u0026quot;com.center.b3expand.mapper.clickhouse\u0026quot;, sqlSessionFactoryRef = \u0026quot;clickHouseSqlSessionFactory\u0026quot;) public class ClickHouseDataSourceConfig { @Bean(\u0026quot;ckDataSourceProperties\u0026quot;) @ConfigurationProperties(prefix = \u0026quot;spring.datasource.clickhouse\u0026quot;) public DataSourceProperties ckDataSourceProperties() { return new DataSourceProperties(); } @Bean(\u0026quot;ckDataSource\u0026quot;) @Qualifier(value = \u0026quot;ckDataSource\u0026quot;) @ConfigurationProperties(prefix = \u0026quot;spring.datasource.clickhouse.hikari\u0026quot;) public HikariDataSource ckDataSource() { return ckDataSourceProperties().initializeDataSourceBuilder().type(HikariDataSource.class).build(); } @Bean(name = \u0026quot;clickHouseSqlSessionFactory\u0026quot;) public SqlSessionFactory clickHouseSqlSessionFactory(@Qualifier(\u0026quot;ckDataSource\u0026quot;) DataSource dataSource) throws Exception { MybatisSqlSessionFactoryBean bean = new MybatisSqlSessionFactoryBean(); bean.setDataSource(dataSource); bean.setMapperLocations(new PathMatchingResourcePatternResolver() .getResources(\u0026quot;classpath:mapper/*.xml\u0026quot;)); bean.getObject().getConfiguration().setMapUnderscoreToCamelCase(true); bean.setTypeAliasesPackage(\u0026quot;com.center.b3expand.po\u0026quot;); return bean.getObject(); } } 数据库配置\nspring: datasource: clickhouse: driverClassName: com.clickhouse.jdbc.ClickHouseDriver enabled: true url: jdbc:clickhouse:http://localhost:8123 username: dev password: 123 hikari: minimum-idel: 20 maximum-pool-size: 20 b3: auto-configured: false url: username: password: hikari: minimum-idel: 20 maximum-pool-size: 20 并发测试 数据基准: 并发8个来进行计算. 每秒并发8个每隔0.5s再触发一次, 则1分钟内执行查询 60 * 2 * 8 = 960次.\n测试方法: 在1分钟内, 3分钟内、5分钟内分别执行960次查询来考核集群的性能.\n查询SQL: 1600万条数据, 15个分组字段聚合查询\n8核与16核压测\n持续时间 8C 吞吐量 次/秒 16C 吞吐量 次/秒 8C 平均响应 秒 16C 平均响应 秒 8C CPU负载 16C CPU负载 8C 内存负载 16C 内存负载 压测 1 Minute 6.5 7.2 3.6 2.78 0.95 0.93 0.38 0.34 压测 3 Minute 5.4 4.8 1.99 2.035 0.80 0.64 0.42 0.40 压测 5 Minute 3.2 3.15 2.179 1.781 0.49 0.41 0.41 0.34 数据显示:\n横向对比:\n在1分钟内16核最多能支持查询400多次（现有硬件不足以支撑继续增加硬件）, 但16核集群表现出更高的吞吐量（+11%）及更好的平均响应时间（+23%） 在3分钟执行960次查询的情况下, 4*16核的集群表现出更好的吞吐量和平均响应时间（但差距不大）, 16核的CPU最高负载要更低（+25%）,内存负载压力区分不大. 在5分钟执行960次查询的情况下,吞吐量及平均响应时间差距不大, CPU和内存的负载曲线接近, 说明压力都不大, 且都能较好的完成查询. 纵向对比:\n8核的吞吐量在5、3、1分钟的压测情况下, 增幅为200% 同样16核的吞吐量的增幅为228%, 对比增加28% 8核的平均响应时间在1、3、5分钟的压测情况下, 增幅为165% 同样16核的平均响应的增幅为156%, 对比降低9% 在设定的查询需求情况下（1600万条数据, 15个分组字段聚合查询）,建议部署规格: 8核16G\n在1分钟情况下, 8核和16核都不能满足要求, 且能支撑的请求数量均为400左右, 差异不大. 在3分钟情况下, 8核CPU使用率80%, 16核CPU使用率为60%, 所以8核CPU也足以支撑业务要求. 在5分钟情况下, 8核的CPU负载为49%, 16核的CPU负载为41%, 使用都未超过50%, 都有足够的剩余. 并发优化\n多分片、多副本, 多次请求可以可以均衡的分担至不同的Node. 从而提升集群的吞吐量 由于clickhouse对CPU消耗巨大,因此通过限流技术控制访问次数保证服务持续有效也将成为一项优化项 在业务场景满足的情况下适当使用缓存技术也是考虑的优化方案之一 对比ES Table 1: 各方面对比说明 因素 说明 建议 性能层面 Clickhouse在处理复杂聚合情况下, 性能表现更好 Clickhouse 开发层面 Clickhouse在完全支持JDBC驱动、学习成本低、快速上手 Clickhouse 数据库层面 Clickhouse在sql兼容性方面比es要好, 易用性、可维护性更佳、clickhouse学习成本更低 Clickhouse 运维层面 Clickhouse对CPU和内存对硬件要求更高, 瞬时对资源消耗更大 Elasticsearch ","permalink":"/posts/clickhouse-tutorial/","series":[],"tags":["Java","Clickhouse"],"title":"Clickhouse Tutorial"},{"authors":[],"categories":[],"content":"最近几年elastic推出了elastic lisence, elastic 认证以对 elastic 的实操性考察难度而闻名. But, 我认为这证明了他们对人才市场挖掘的雄心.\nIntroduction 记得多年以前看过 Elastic 官方的概述, 其中讲到了 Elastic 公司的发展. Elastic 是一家典型的以开源软件为模型的盈利性的公司. Elastic 早年在发展期间进行了很多免费的公开培训, 实际上培训的过程首先是推广了 Elastic 的知名度, 其次 Elastic 举办方也在这期间发掘优秀的人才收为己用, 是一种非常卓越的招聘手段. 最近几年 Elastic 又推出了Elastic Lisence, Elastic 认证以对 Elastic 的实操性考察难度而闻名. 我认为这证明了他们对人才市场挖掘的雄心.\nElastic是一家快速发展的公司, 唯一想吐槽的点我认为其文档过于庞杂. 当然些事情丝毫不会影响到Elastic在搜索领域中的领先的市场份额和排名.\nInstall \u0026amp; config use package manager\n安装步骤:\n下载deb安装包\n执行安装\n修改配置, 最简单的设置所有ip可访问, 不添加安全权限\n设置操作系统ulimit\n启用elasticsearch服务\n启动服务\nwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.9.1-amd64.deb sudo dpkg -i elasticsearch-8.8.2-amd64.deb sudo systemctl enable elasticsearch.service sudo vim /etc/elasticsearch/elasticsearch.yml # setting your config sudo su ulimit -n 65535 su elasticsearch sudo systemctl restart elasticsearch sudo journalctl \u0026ndash;unit elasticsearch\nuse uninsatll package\nhttps://www.elastic.co/downloads/past-releases/elasticsearch-8-8-2\nwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.8.2-linux-x86_64.tar.gz tar -xvf elasticsearch-8.8.2-linux-x86_64.tar.gz Directory layout of Debian package\nhttps://www.elastic.co/guide/en/elasticsearch/reference/8.9/deb.html#deb-layout\nbin /usr/share/elasticsearch/bin\nUnInstall sudo dpkg -P elasticsearch # uninsatll sudo apt-get --purge autoremove elasticsearch sudo rm -rf /var/lib/elasticsearch/ sudo rm -rf /etc/elasticsearch Architecture Elastic search 在存放数据的时候, 需要有先将数据存储至主分片, 再根据复制规则将数据存储至不同的子节点.\n路由只有到了elasticsearch的协调节点以后才知道具体应该到哪个节点写或者具体应该从哪些节点读. 在发送请求时这些信息都是不明确的.\n协调节点: 用户可以访问任意一个节点来获取elastic的集群的数据 分片数量: 写数据的时候有路由规则决定如何路由至某个特定的分片来写入 副本数量: 读数据的时候根据数据副本存放的节点来进轮询路由访问 分词器: IK分词器, 分词粗细粒度的设置, 可设置扩展词汇（IK提供的功能, ikplugin/config/custom.dic） 一致性: one, 只有当主节点存储成功则客户端就可以查询、all, 只有所有的子节点都成功同步好数据以后客户端才能查询这个数据 Restful Api Table 1: the difference between restful methodes post 非冥等 put 冥等 #创建索引, 并设置分片数量 , 分片数量是影响查询性能的主要因素之一 PUT http://cloudtencent.com:9200/shopping { \u0026quot;settings\u0026quot;: { \u0026quot;number_of_shards\u0026quot;: 15 } } #将一个索引的数据同步至另外一个索引, 设置一次性按多少条记录来提交 POST http://cloudtencent.com:9200/_reindex?slices=9\u0026amp;refresh\u0026amp;wait_for_completion=false { \u0026quot;source\u0026quot;: { \u0026quot;index\u0026quot;: \u0026quot;shopping\u0026quot;, \u0026quot;size\u0026quot;: 10000 }, \u0026quot;dest\u0026quot;: { \u0026quot;index\u0026quot;: \u0026quot;shopping_test_15\u0026quot; } } #设置doc的副本 PUT http://cloudtencent.com:9200/shopping/_settings { \u0026quot;number_of_replicas\u0026quot;: 1 } #查看索引 GET http://cloudtencent.com:9200/shopping #查看所有索引 GET http://cloudtencent.com:9200/_cat/indices?v #删除索引 DELETE http://cloudtencent.com:9200/shopping #创建数据 # POST http://cloudtencent.com:9200/shopping/_create POST http://cloudtencent.com:9200/shopping/_doc Content-Type: application/json { \u0026quot;title\u0026quot;:\u0026quot;小米手机\u0026quot;, \u0026quot;category\u0026quot;:\u0026quot;小米\u0026quot;, \u0026quot;image\u0026quot;:\u0026quot;http://www.baidu.com\u0026quot;, \u0026quot;price\u0026quot;:39999.00 } #创建数据带id POST http://cloudtencent.com:9200/shopping/_doc/1002 Content-Type: application/json { \u0026quot;title\u0026quot;:\u0026quot;荣耀手机\u0026quot;, \u0026quot;category\u0026quot;:\u0026quot;华为\u0026quot;, \u0026quot;image\u0026quot;:\u0026quot;http://www.baidu.com\u0026quot;, \u0026quot;price\u0026quot;:19999.00 } #查询文档,指定id GET http://cloudtencent.com:9200/shopping/_doc/1001 #查询所有的数据 GET http://cloudtencent.com:9200/shopping/_search #修改数据 PUT http://cloudtencent.com:9200/shopping/_doc/1001 Content-Type: application/json { \u0026quot;title\u0026quot;:\u0026quot;小米手机v3\u0026quot;, \u0026quot;category\u0026quot;:\u0026quot;小米\u0026quot;, \u0026quot;image\u0026quot;:\u0026quot;http://www.baidu.com\u0026quot;, \u0026quot;price\u0026quot;:29999.00 } # 部分更新 POST http://cloudtencent.com:9200/shopping/_update/1001 Content-Type: application/json { \u0026quot;doc\u0026quot;: { \u0026quot;title\u0026quot;: \u0026quot;小米手机v4\u0026quot; } } # 删除数据 DELETE http://cloudtencent.com:9200/shopping/_doc/1001 # 条件查询 GET http://cloudtencent.com:9200/shopping/_search Content-Type: application/json { \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;category\u0026quot;: \u0026quot;小米\u0026quot; } } } # 全查询 GET http://cloudtencent.com:9200/shopping/_search Content-Type: application/json { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: { } } } # 分页查询 GET http://cloudtencent.com:9200/shopping/_search Content-Type: application/json { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} }, \u0026quot;from\u0026quot;: 0, \u0026quot;size\u0026quot;: 2 } # 选择列及排序 GET http://cloudtencent.com:9200/shopping/_search Content-Type: application/json { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} }, \u0026quot;from\u0026quot;: 0, \u0026quot;size\u0026quot;: 3, \u0026quot;_source\u0026quot;: [ \u0026quot;title\u0026quot; ], \u0026quot;sort\u0026quot;: { \u0026quot;price\u0026quot;: { \u0026quot;order\u0026quot;: \u0026quot;asc\u0026quot; } } } # 多条件查询及过滤 GET http://cloudtencent.com:9200/shopping/_search Content-Type: application/json { \u0026quot;query\u0026quot;: { \u0026quot;bool\u0026quot;: { \u0026quot;should\u0026quot;: [ { \u0026quot;match\u0026quot;: { \u0026quot;category\u0026quot;: \u0026quot;小米\u0026quot; } }, { \u0026quot;match\u0026quot;: { \u0026quot;category\u0026quot;: \u0026quot;华为\u0026quot; } } ], \u0026quot;filter\u0026quot;: { \u0026quot;range\u0026quot;: { \u0026quot;price\u0026quot;: { \u0026quot;gt\u0026quot;:30000 } } } } } } # 全文查询,小华拆成小、华然后再做全文匹配 # 高亮显示 GET http://cloudtencent.com:9200/shopping/_search Content-Type: application/json { \u0026quot;query\u0026quot;: { \u0026quot;match_phrase\u0026quot;: { \u0026quot;category\u0026quot;: \u0026quot;华为\u0026quot; } }, \u0026quot;highlight\u0026quot;: { \u0026quot;fields\u0026quot;: { \u0026quot;category\u0026quot;: {} } } } # 聚合操作 GET http://cloudtencent.com:9200/shopping/_search Content-Type: application/json { \u0026quot;aggs\u0026quot;: { \u0026quot;price_group\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;price\u0026quot; } } }, \u0026quot;size\u0026quot; : 0 } # 平均操作 # GET http://cloudtencent.com:9200/shopping/_search GET http://cloudtencent.com:9200/shopping/_search Content-Type: application/json { \u0026quot;aggs\u0026quot;: { \u0026quot;price_avg\u0026quot;: { \u0026quot;avg\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;price\u0026quot; } } }, \u0026quot;size\u0026quot; : 0 } #创建索引 PUT http://cloudtencent.com:9200/user #elastic 映射 PUT http://cloudtencent.com:9200/user/_mapping Content-Type: application/json { \u0026quot;properties\u0026quot;: { \u0026quot;name\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;index\u0026quot;: true }, \u0026quot;sex\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;index\u0026quot;: true }, \u0026quot;tel\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;index\u0026quot;: false } } } # 查询映射 GET http://cloudtencent.com:9200/user/_mapping # 增加数据 POST http://cloudtencent.com:9200/user/_doc/1001 Content-Type: application/json { \u0026quot;name\u0026quot;:\u0026quot;小米\u0026quot;, \u0026quot;set\u0026quot;:\u0026quot;男\u0026quot;, \u0026quot;tel\u0026quot;:\u0026quot;18729038467\u0026quot; } #查询 GET http://cloudtencent.com:9200/user/_search Content-Type: application/json { \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;tel\u0026quot;: \u0026quot;18729038467\u0026quot; } } } Java SDK Dependency\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.elasticsearch.client\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;elasticsearch-rest-high-level-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;7.17.12\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--springboot的elasticsearch服务--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-elasticsearch\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;jakarta.json\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jakarta.json-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;jakarta.json\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jakarta.json-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.5.13\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Configure\nHere we provide a bean named ElasticsearchClient.\npackage pkg.service; import org.apache.http.HttpHost; import org.apache.http.auth.AuthScope; import org.apache.http.auth.UsernamePasswordCredentials; import org.apache.http.client.CredentialsProvider; import org.apache.http.impl.client.BasicCredentialsProvider; import org.elasticsearch.client.RestClient; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import co.elastic.clients.elasticsearch.ElasticsearchClient; import co.elastic.clients.json.jackson.JacksonJsonpMapper; import co.elastic.clients.transport.ElasticsearchTransport; import co.elastic.clients.transport.rest_client.RestClientTransport; /** * @time 2023-09-04 15:02:32 **/ @Configuration public class ElasticSearchConf { @Bean public ElasticsearchClient restClient() { final CredentialsProvider credentialsProvider = new BasicCredentialsProvider(); credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(\u0026quot;elastic\u0026quot;, \u0026quot;*****\u0026quot;)); HttpHost nodeNodotOne = new HttpHost(\u0026quot;172.10.0.1\u0026quot;, 9200); HttpHost nodeNodotTwo = new HttpHost(\u0026quot;172.10.0.2\u0026quot;, 9200); HttpHost nodeNodotThree = new HttpHost(\u0026quot;172.10.0.3\u0026quot;, 9200); HttpHost[] elasticSearchNodes = new HttpHost[] { nodeNodotOne, nodeNodotTwo, nodeNodotThree }; // support multiple node RestClient httpClient = RestClient.builder(elasticSearchNodes) .setHttpClientConfigCallback(httpClientBuilder -\u0026gt; { httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider); return httpClientBuilder; }).build(); ElasticsearchTransport transport = new RestClientTransport( httpClient, new JacksonJsonpMapper()); ElasticsearchClient esClient = new ElasticsearchClient(transport); return esClient; } } Usage\npackage pkg.controller; import java.io.IOException; import javax.validation.Valid; import com.longda.fegion.dto.Result; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import co.elastic.clients.elasticsearch.ElasticsearchClient; import co.elastic.clients.elasticsearch._types.ElasticsearchException; import co.elastic.clients.elasticsearch.core.GetResponse; import io.swagger.annotations.Api; import lombok.extern.slf4j.Slf4j; import pkg.po.Shopping; /** * @since 2023-09-04 16:04:58 **/ @Slf4j @Api(\u0026quot;ElasticSearchController\u0026quot;) @RestController @RequestMapping(\u0026quot;ElasticSearchController\u0026quot;) public class ElasticSearchController { @Autowired ElasticsearchClient restClient; /** * ElasticSearchController get */ @GetMapping(\u0026quot;/get\u0026quot;) public Result\u0026lt;Integer\u0026gt; get(@Valid String id) { try { GetResponse\u0026lt;Shopping\u0026gt; getResponse = restClient.get(getRequest -\u0026gt; getRequest.index(\u0026quot;shopping\u0026quot;).id(id), Shopping.class); Shopping source = getResponse.source(); log.info(\u0026quot;== document source: {}, response: {}\u0026quot;, source, getResponse); } catch (Exception e) { log.error(\u0026quot;==== [error]: {}\u0026quot;, e); } return Result.success(); } } Sqlquery\nTable 2: sql语法支持情况 GRAMMER DESC SUPPORT select * wildcard ✓ select money more_money rename ✓ select * from (select \u0026#x2026;) subquery ✓ count count ✓ join index relation ྾ case when condition ✓ in \u0026#xa0; ✓ time \u0026gt; \u0026rsquo;2023-09-03T23:59:59\u0026rsquo; time range ✓ group by a,b,c multiple group ✓ max、min、sum、avg.. aggregation ✓ /** * ElasticSearchController by sql */ @GetMapping(\u0026quot;/testsql\u0026quot;) public Result\u0026lt;Void\u0026gt; testSql() { String sql = \u0026quot;select count(*) from tmp_20230906\u0026quot;; try { QueryResponse queryResp = restClient.sql() .query(query -\u0026gt; query .format(\u0026quot;json\u0026quot;) .query(sql)); log.info(\u0026quot;==== [log]: {}\u0026quot;, queryResp.rows()); return Result.success(); } catch (Exception e) { log.error(\u0026quot;==== [error]: {}\u0026quot;, e); return Result.error(ResultEnum.COM_ERROR); } } Performance 经过测试, elasticsearch的性能表现良好; 但仍然没达到秒级以内\n原因: 使用了15个字段进行分组, 这在实际业务中属于极端情况了, 一个正常的查询比如订单、出库单, 在数据库设计良好的情况下应该不会冗余这么多的字段.\nTable 3: elasticsearch集群配置及sql情况 因素 值 Elastic集群数 3 主机内存 32G 主机CPU 奔腾？ 测试数据量 1600万 测试字段 共60个 分组字段 group by 共15个 聚合分析字段 40个, 各种case when 加减剩除 Table 4: 测试结果 Database Engin Initial Cost Cached Cost ES_TABLE ES1shard 20.5 0.1 tmp_20230905 ES3shard 9.5 0.1 tmp_test ES6shard 4.585401 0.1 tmp_20230907 ES9shard 3.468439 0.1 tmp_test_9 ES15shard 4.218455s 0.1 tmp_test_15 ","permalink":"/posts/elasticsearch-part1/","series":[],"tags":["Java","Elastic-Search"],"title":"ElasticSearch Part1"},{"authors":[],"categories":[],"content":"Vimium C 解决了在 Chrome 中使用 Vimium 部分页面不生效的问题, 让全键盘流变得更加丝滑.\n缘起 由于常年使用 Emacs, 对于一切全键盘的操作都特别兴奋, 浏览器是日常工作学习中必不可少的工具. 最早我使用Vimium. 最近开始使用Vimium C, Vimium C 解决了在chrome中使用Vimium多年来的小部分困扰, 让全键盘流变得更加丝滑👍.\nVimium Vimium 提供了在浏览器中使用键盘操作的最通用、常见的功能. 这里列出一些我用到的最多的特性.\nTable 1: Vimium 常见操作快捷键速览 features shortkey next tab K previous tab J close Tab x new tab t jump to link f scroll up u scroll down d copy current url yy search char / next search n previous search N 设置\n让本地文件也能使用vimium的快捷键, 需要在插件管理内设置: Allow access to file URLs 在vimium的option设置页设置new tab: any website. 这样在new tab打开时就也能使用vimium的快捷键. 其他的.. 好像没了 问题\nvimium 使用的越多, 其中一个问题凸显的越明显. 那就是vimium在 chrome 的某些自定义页面不可使用, 比如 chrome的插件设置页, 或者chrome的默认new tab页, 每当碰到这些页面的时候,要么我们使用 `command + l` 跳转至一个新的网页, 要么就只能去碰鼠标了. 然而在vimium中这个问题几乎无解.\nVimium C Vimium C 号称是Vimium 的加强版. 其中就解决了Vimium的部分页面失效的问题, 而且其搜索比Vimium要更好用.Vimium C 的快捷键和Vimium在我上面提到的范围内是一模一样的, 这几乎是可以无感平替.其次在Vimium C 内可以配置在chrome的所有页面都有效, 包括chrome的setting页. 大家设置好就纵情体验吧!\n设置\n在Vimium C 内设置在chrome的插件页生效: option\u0026gt;Advanced Options\u0026gt; Run on chrome://*/* pages (need #extensions-on-chrome-urls) 在Vimium C 内设置在chrome的新tab页生效: option\u0026gt;Run on Chrome’s native New Tab Page (need #extensions-on-chrome-urls) 设置上面两项的前提, 先设置 chrome://flags/\u0026gt;Extensions on chrome:// URLs\u0026gt;enable, 并重启就可以了. 在Vimium C 内禁用b按键: option\u0026gt;Custom key mappings\u0026gt;unmap b, 保存生效 ","permalink":"/posts/vimiumc/","series":[],"tags":["Emacs","Chrome"],"title":"VimiumC"},{"authors":[],"categories":[],"content":"在使用 doom emacs 的时候 workspace 是我们经常使用到的功能.那么如何在进行buffer切换时找到自己想要的空间呢？比如快速找vterm这个空间, 或者说http这个空间呢？\n痛点 在使用 doom emacs 的时候 workspace 是我们经常使用到的功能. 但是默认的workspace在设置workspace的名称的时候使用了编号(#No.)进行命名,没有实际的上下文含义.\n我经常开多个workspace, 频繁的在多个workspace中切换. 一般在做后端java开发的时候,我习惯至少要开四个workspace, 工作中往往需要再给空间另外命名. 但每次关闭又需要重新命名操作, 非常的麻烦.\nlsp-java 代码工程空间 ejcsql 数据库空间 rest-client 作为测试接口的空间 org-mode 文档空间 那么如何在进行buffer切换时找到自己想要的空间呢？比如快速找vterm这个空间, 或者说http这个空间呢？\n解决 其实最终期望的效果是释放手动设置workspace的名称这个动作, 尝试用elisp来帮我们实现利用当前buffer的名称作为workspace的名称.\n可以利用 pre-command-hook 钩子在每次执行命令的时候对 workspace 的名称进行一次设置. 为了提升效率, 当判定出buffer-name与workspace-name相同时, 则不需要再次设置workspace的名称. 此外在进行recentf、fzf等操作的时候 workspace 名称无需跟随改变. 则有了下面的代码.\n需要注意的是workspace要求名称唯一,因此如果我们在2个buffer中打开了同一个文件此时又将workspace的名称设置成了buffer的名称则workspace会提示异常（名称未发生改变）.\n到这里猛然发现想要的不就是 tab 标签栏的效果吗？Anyway 就是习惯了看 workspace ~ happy.\n(add-hook 'pre-command-hook (lambda () (if (or (eq (buffer-name) (+workspace-current-name)) (string-match \u0026quot;*Minibuf\u0026quot; (buffer-name)) ) nil (+workspace:rename (buffer-name))))) eslip代码学习 需要注意的是, string-match 这个函数当不匹配的时候就返回nil,匹配的时候返回数字. 其实它的结果可直接被if语句用于判断条件的.无需再进行转换了.另外pre-command-hook和post-command-hook这两个hook都可以实现本次的功能, 但post-command-hook时而会出现一些异常的情况.这个与两个hook的执行时间有关系, pre-command-hook 是在comman执行之前就先执行hook, post-command-hook是在command执行之后才执行的hook.实践证明hook应该要放在执行前还是执行后并无实际的影响.\n铵键配置 同时也分享下neo-emacs中对于workspace快捷键的设置. 最常用的就是左右切换workspace了, 因此设置了K、J来进行切换.\n还有对workspace进行位置的移动,这其实是一个低频的功能.因此设置在了 command+k 、 command+j 来分别左移和右移.\n(map! :n \u0026quot;K\u0026quot; '+workspace/switch-right ) (map! :n \u0026quot;J\u0026quot; '+workspace/switch-left ) (map! :n \u0026quot;s-k\u0026quot; '+workspace/swap-right ) (map! :n \u0026quot;s-j\u0026quot; '+workspace/swap-left ) 其他问题 如果buffer的名称过长了会占用底部太多的空间. 这个还比较好优化 每次 workspace-rename 以后,该 workspace 的排序被移动到了最右边. workspace 位置产生移动会打乱我们对空间顺序的固有思维. 暂时无解答 如果在2个不同的workspace中打开相同的文件, 程序会自动设置workspacename为文件名, 但是workspace不允许设置为相同,因此会出现buffer切换了但是workspacename没更改的情况,也算是一种错乱. ","permalink":"/posts/emacs-workspace/","series":[],"tags":["Emacs","Doom"],"title":"Emacs Workspace"},{"authors":[],"categories":[],"content":"Hugo can build a personal blog conveniently and quickly, providing comments, categories, searches, skins, subscriptions and other functions. Its open source code allows users to customize its default behavior at will.\nprinciple Hugo site root directory contains the whole meta data, the posts\u0026rsquo; origin markdown file, themes static resources, avatar iamge etc.Just use command hugo on site root directory hugo will generate a site publish directory named public.So usually we do not modify pulish directory directly.Use 2 git repository is necessar they are hugo site root and publich directory.Publich hugo website in a particular domain,in additional to config a A record with the domain name vendor,more importantly you need config that on github gitpages.After that there will add a CNAME file located at public director.Never remove the CNAME file otherwise website will occur 404.\nnew post Table 1: create a new post steps step process location illustrate 1 hugo new posts/post-name.md your site root path your post content 2 draft: false post-name.md header ready for public or not 3 toc: true post-name.md header title of content or not 4 summarize \\n \u0026lt;!\u0026#x2013;more\u0026#x2013;\u0026gt; post-name.md header after summarize of this post 5 revise your outline every outline with # make sure the outline is correct 6 delete markdown\u0026rsquo;s toc post-name.md header after use hugo\u0026rsquo;s toc exclusively 7 generate html file public's parent generate in public dir --- title: \u0026quot;Sony A7c 入门\u0026quot; date: 2023-08-21T08:46:42+08:00 draft: false toc: true --- Sony a7c 相机入门基础知识整理 \u0026lt;!--more--\u0026gt; \u0026lt;a id=\u0026quot;orgd017a38\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; ## devlog 设置 ... quote images The image need located at %yoursite%/public/posts/postname/ .\nUsually I put the image into a sub directory image , thus it looks like %yoursite%/public/posts/postname/image/pattern.png .\ngenerate Use hugo to generate html content in public directory.Command hugo for incremental construction that means some of the content will not generated, like avatar image. If want rebuild the whole public directory, firstly use hugo --cleanDestinationDir to clean the public,and then use hugo to build from scratch. Do not use hugo server, hugo server will startup a localserver for review.it leads all the static resrouces\u0026rsquo; reference to localhost.This will makes online website occur 404 error.\ncss customize Create your customize css file at %yoursite%/static/css/default.css .\nput default css into the %yoursite%/themes/hugo-eureka/layouts/_default/baseof.html.\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;/css/default.css\u0026quot;\u0026gt; tbody, th, tbody td { border: 1px solid #666; } tbody tr:nth-child(odd) { background-color: var(--color-primary-bg) } ","permalink":"/posts/hugo-usage/","series":[],"tags":["Hugo","Org"],"title":"Hugo Usage"},{"authors":[],"categories":[],"content":"Sony a7c 相机入门基础知识整理\ndevlog 设置 设置：pp9 ，伽玛：HLG3\nISO: 800-1000\n白平衡模式：荧光灯：冷白色\n对焦模式：AF-C\n对焦区域：广域\n曝光补偿：0\n测光模式：整个屏幕平均/点测光标准\n相机拍摄模式 模式 说明 AUTO 自动模式 P ISO先决模式 A 光圈先决模式 S 快门先决模式 M 全手动模式 ISO 数值 效果 100 户外晴天 400 户外阴天 800 良好 1600 室内 3200 晚上街拍 更高 不建议 快门 快门速度 适合场景 1/25 静物 1/50 人像 1/250 扫街 1/1000 体育 1/2 车流 10s 星空 15s 流水 30s 烟花 F光圈 F值越大、光圈越小\n控制进光量和景深\nF值越大, 景深越大, 模糊越不明显\nF值 场景 1.4 人像 2.8-4 街拍 8-16 风景 让图更亮 按优先顺序进行调整\n1、降低快门速度\n2、开大光圈\n3、调高ISO\n让图更暗 按优先顺序进行调整\n1、降低ISO\n2、增加快门速度\n3、减小光圈\n说明图 ","permalink":"/posts/sony-a7c-%E5%85%A5%E9%97%A8/","series":[],"tags":["A7c"],"title":"Sony A7c 入门"},{"authors":[],"categories":[],"content":"mac stage manager 提供了一个真正无打扰的工作环境.\n最近使用 macos 的 stage manager, 感觉十分清爽. stage manager 提供了一个真正无打扰的环境, 在此模式下可以屏蔽其他的窗口, 只显示当前窗口. 甚至可以屏蔽桌面的文件, 因此好看的壁纸可以 “无污染” 的展示了. 不过非常可惜的是, stage manager 未提供切换不同 application 的快捷键设置. 倘若使用 Alfred 等软件又无法一键切换应用, 幸运的是我们可以使用 mac 提供的 Automator 来实现一键切换应用.\ncontent 尝试一 首先, 打开 Automator.app \u0026gt; File new (command N) \u0026gt; Quick Action \u0026gt; Run AppleScript\n输入如下代码, 并使用播放按键, 进行简单测试. 如果能成功切换至 Emacs 说明程序生效了.\n接下来将此 Automator 程序保存并命名 OpenEmacs\n1 on run {input, parameters} 2 3 (* Your script goes here *) 4 tell application \u0026quot;Emacs\u0026quot; 5 activate 6 end tell 7 8 end run 其次,我们为 OpenEamcs 设置一个快捷键. 打开 System Settings.app \u0026gt; Keyboard \u0026gt; Keyboard Shortcuts \u0026gt; Service \u0026gt; General\n选择 OpenEmacs 并设置快捷键. 保存后使用快捷键进行测试.\n我自己将 command + R 设置为 Chrome 的快捷键. 将 command + K 设置为 Emacs 的快捷键.\n注意 Keyboard 的快捷键可能和系统的快捷键以及和app内置的快捷键冲突,\n经测试发现 Keyboard 的快捷键有先级比较低, 如过冲突则按键事件无法抵达 Automator.\n因此需要根据大家的应用情况设置合理的快捷键\n尝试二 其灵感来源于某个APP, 可以使用一个组合键来对某个应用进行 Toggle Visual. Toggle 这个单词大家应该不陌生, 就是切换的意思.\n使用同一个按键当应用此时正打开的时则将其隐藏, 当此时应用正隐藏时将其放在桌面最上层.\n在我的 laptop 上, 我将 Emacs 绑定至 command + k 和 Chrome 绑定至 command + h, 键位冲突较少可供大家参考.\n1 tell application \u0026quot;System Events\u0026quot; 2 if visible of application process \u0026quot;Emacs\u0026quot; is true then 3 set visible of application process \u0026quot;Emacs\u0026quot; to false 4 else 5 tell application \u0026quot;Emacs\u0026quot; to activate 6 end if 7 end tell 尝试三 尝试二的优化, 尝试二使用了 applescript 带来的问题是, 切换应用的速度明显能感觉到有延迟.网上搜索到了使用 hammerspoon 的方案, 亲自测试了下速度非常快, 可以说是终级解决方案了.\ntoggleApp = function(appName, launch) launch = launch or false local app = hs.application.get(appName) if app then if app:isFrontmost() then app:hide() else app:activate() end else if launch then hs.application.launchOrFocus(appName) else hs.alert.show(\u0026quot;App '\u0026quot; .. appName .. \u0026quot;' is not loaded!\u0026quot;) end end end hs.hotkey.bind({\u0026quot;cmd\u0026quot;}, \u0026quot;K\u0026quot;, function() toggleApp(\u0026quot;Emacs\u0026quot;) end) hs.hotkey.bind({\u0026quot;cmd\u0026quot;}, \u0026quot;F\u0026quot;, function() toggleApp(\u0026quot;Finder\u0026quot;) end) hs.hotkey.bind({\u0026quot;cmd\u0026quot;}, \u0026quot;R\u0026quot;, function() toggleApp(\u0026quot;Google Chrome\u0026quot;) end) ","permalink":"/posts/stage%E5%BF%AB%E6%8D%B7%E9%94%AE/","series":[],"tags":["Mac","Emacs"],"title":"Macos Stage 快捷键"},{"authors":[],"categories":[],"content":"是一款脚本绘图语言程序, 提供丰富的特性, 其中我最喜欢的功能包括可生成箭头流动效果\nTable of Contents Introduction Usage Org mode TALA License Introduction D2 是一款脚本绘图语言程序, 提供丰富的特性 , 其中我最喜欢的功能包括可生成箭头流动效果,简洁的语法, 避免使用 quote (引号) 对空格的支持, 多类型的布局等等, 我们首先说下 D2 的布局, 一共分为3种布局\ndagre ,一种有向图, 基于 Graphviz’s DOT 算法不布局, 如果你很熟悉dot 不妨试试这种布局 ELK ,也是一种有向图, 但官方宣称比dagre更成熟 TALA, 全新的 付费 布局引擎, 官方宣称是特别针对软件框架图而设计的布局 综合来说, 其实官方也没说的很明白,不过由于 TALA 是付费的布局,有专门的网站和演示案例. 确实让人心动.幸运的是虽说 TALA 是付费的,但他却提供软件的源代码,我们仍然可以使用 TALA 布局只不过在生成出来的图片中含有 LICENSE COPY 的水印（后面讲怎么去除）.\nUsage 你的第一个D2架构图,代码如下.\ndirection 代表了布局的方向, style.fill 代表了背景图与 dot 和 plantuml 一样,都可以支持透明背景 transparent. d2支持我们定义一些预置的 class 样式,见classes代码片段. 连接线的样式中有我们喜闻乐见的 style.animated 这就是连接线动态效果的设置. 在最新的 v0.6.0 中,可以通过在vars对象中的键值对来申明变量,这极大方便了我们在画图时对颜色和属性的重复引用. 在最新的 v0.6.0 中,可以使用通配符来指定节点的样式 *.style.fill（目前仅针支持节点,不支持连接线）. 接下来我声明了A、B、C 3个节点,并且分别引用 2dn(2d node) 和 3dn(3d node).\ndirection : right style.fill : transparent vars: { nodecolor : \u0026quot;#E67E22\u0026quot; style-stroke : \u0026quot;#17202A\u0026quot; style-stroke-width : 2 style-fill-pattern : dots style-shadow : true line-style-fill : \u0026quot;#884EA0\u0026quot; } classes: { 2dn: { style.multiple : true } 3dn: { style.3d : true } 2de: { style.animated : true style.stroke-width : ${style-stroke-width} style.stroke : ${line-style-fill} } } A : { class : 2dn } B : { class : 3dn } C : { class : 3dn } A -\u0026gt; B -\u0026gt; C -\u0026gt; D{ class : 2de } *.style.fill : ${nodecolor} *.style.stroke : ${style-stroke} *.style.stroke-width : ${style-stroke-width} *.style.fill-pattern : ${style-fill-pattern} *.style.shadow : ${style-shadow} Org mode 最后分享如何在 org mode 中使用d2.\n在 org mode 中引入新的 src block 执行代码块,你可以使用如下代码作为参考.我在这里增加了d2的手绘风格的代码,其原因是d2的部分设置需要在命令行上进行设置.类似于图片间宽、布局引擎、动画速率等参数均是通过命令行参数来设置的,无法在src block内进行设定.因此我在fish内增加了软连接带入默认参数,以此来实现在org mode中进行不同风格的d2设置切换.\nalias ds2 \u0026quot;~/soft/d2-v0.6.0/bin/d2 --sketch --animate-interval=1400 -l elk -c --pad 0\u0026quot; ;;; ds2.el --- Babel Functions for ds2 -*- lexical-binding: t; -*- ;; Copyright (C) 2009-2022 Free Software Foundation, Inc. ;; Author: Eric Schulte ;; Maintainer: Justin Abrahms \u0026lt;justin@abrah.ms\u0026gt; ;; Keywords: literate programming, reproducible research ;; URL: https://orgmode.org ;; This file is part of GNU Emacs. ;; GNU Emacs is free software: you can redistribute it and/or modify ;; it under the terms of the GNU General Public License as published by ;; the Free Software Foundation, either version 3 of the License, or ;; (at your option) any later version. ;; GNU Emacs is distributed in the hope that it will be useful, ;; but WITHOUT ANY WARRANTY; without even the implied warranty of ;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the ;; GNU General Public License for more details. ;; You should have received a copy of the GNU General Public License ;; along with GNU Emacs. If not, see \u0026lt;https://www.gnu.org/licenses/\u0026gt;. ;;; Commentary: (require 'org-macs) (org-assert-version) (defvar org-babel-default-header-args:ds2 '((:results . \u0026quot;file\u0026quot;) (:exports . \u0026quot;results\u0026quot;)) \u0026quot;Default arguments to use when evaluating a ds2 source block.\u0026quot;) (defun org-babel-expand-body:ds2 (body params) \u0026quot;Expand BODY according to PARAMS, return the expanded body.\u0026quot; (let ((vars (org-babel--get-vars params))) (mapc (lambda (pair) (let ((name (symbol-name (car pair))) (value (cdr pair))) (setq body (replace-regexp-in-string (concat \u0026quot;$\u0026quot; (regexp-quote name)) (if (stringp value) value (format \u0026quot;%S\u0026quot; value)) body t t)))) vars) body)) (defun org-babel-execute:ds2 (body params) \u0026quot; This function is called by `org-babel-execute-src-block'.\u0026quot; (let* ((out-file (cdr (or (assq :file params) (error \u0026quot;You need to specify a :file parameter\u0026quot;)))) (cmdline (or (cdr (assq :cmdline params)))) (cmd (or (cdr (assq :cmd params)) (concat \u0026quot;ds2 \u0026quot; \u0026quot;\u0026quot;))) (coding-system-for-read 'utf-8) ;use utf-8 with sub-processes (coding-system-for-write 'utf-8) (in-file (org-babel-temp-file \u0026quot;ds2-\u0026quot;))) (with-temp-file in-file (insert (org-babel-expand-body:ds2 body params))) (org-babel-eval (concat cmd \u0026quot; \u0026quot; (org-babel-process-file-name in-file) \u0026quot; \u0026quot; cmdline \u0026quot; \u0026quot; (org-babel-process-file-name out-file)) \u0026quot;\u0026quot;) nil)) ;; signal that output has already been written to file (defun org-babel-prep-session:ds2 (_session _params) \u0026quot;Return an error because ds2 does not support sessions.\u0026quot; (error \u0026quot;ds2 does not support sessions\u0026quot;)) (provide 'ds2) TALA License 经常性的在 org mode 中导出 html ,遇到最多的问题是,当我们把 html 发送给其他人时,里面的图片就不能打开了.这是因为我们发送出去的仅是 html 代码, 只包括了图片地址,不包括图片的内容. 为了解决这个问题,我们可以在生成 html 的同时将图片以base64的形式直接嵌入至html文件内.\nd2 的 TALA 布局是一个收费的布局引擎,但幸运的是尽管他收费,但是却开源.我们仍然可以下载TALA引擎的二进制执行文件,只不过在未授权的时候会在图片中生成 UNLICENSED COPY 的水印.svg的水印很好去除,用text-mode打开文件,找到水印字样删除即可.利用上面的在将图片转换成BASE64的时候我们仅需要将 UNLICENSED COPY 替换成空就完成了水印去除了.\n;; html image base64 (defun org-html--format-image-old (source attributes info) (org-html-close-tag \u0026quot;img\u0026quot; (org-html--make-attribute-string (org-combine-plists (list :src source :alt (if (string-match-p (concat \u0026quot;^\u0026quot; org-preview-latex-image-directory) source) (org-html-encode-plain-text (org-find-text-property-in-string 'org-latex-src source)) (file-name-nondirectory source))) (if (string= \u0026quot;svg\u0026quot; (file-name-extension source)) (org-combine-plists '(:class \u0026quot;org-svg\u0026quot;) attributes '(:fallback nil)) attributes))) info)) (defun org-org-html--format-image (source attributes info) ;; doc (if (string-match \u0026quot;http\u0026quot; source) (org-html--format-image-old source attributes info) (format \u0026quot;\u0026lt;img src=\\\u0026quot;data:image/%s+xml;base64,%s\\\u0026quot;%s width=%s /\u0026gt;\u0026quot; (or (file-name-extension source) \u0026quot;\u0026quot;) (base64-encode-string (with-temp-buffer (insert-file-contents-literally source) (string-replace \u0026quot;UNLICENSED COPY\u0026quot; \u0026quot; \u0026quot; (buffer-string)))) (file-name-nondirectory source) \u0026quot;100%\u0026quot;))) (advice-add #'org-html--format-image :override #'org-org-html--format-image) ","permalink":"/posts/%E4%BD%BF%E7%94%A8d2%E7%BB%98%E5%9B%BE/","series":[],"tags":["Org","Emacs"],"title":"使用d2绘图"},{"authors":[],"categories":[],"content":"泛微OA，计算员工每月应出勤天数， oracle 数据库\nTable of Contents 基本需求 oracle 日期基本处理 附件泛微考勤表 E-R 图 oracle 结合泛微 OA 实现考勤统计 计算方法 sql 实现 基本需求 计算员工每月应出勤天数，分 A、B 2 种算法，考虑假期表；\nA 地出勤, 统计每周 1-5 汇总天数 - 当月国家法定假日天数\nB 地出勤, 统计每周 1-6 汇总天数 - 当月国家法定假日天数\noracle 日期基本处理 TO_CHAR(date_value, 'D') -- 转星期数 2023-06-05 -\u0026gt; 1-7 数字 (select TRUNC(TO_DATE('2023', 'YYYY'), 'YYYY') + LEVEL - 1 AS date_value FROM dual CONNECT BY LEVEL \u0026lt;= 365) calendar -- 生成 2023 全年的日历记录 TO_DATE(ho.holidaydate,'yyyy-mm-dd') -- 字符串转日期 EXTRACT(YEAR FROM date_value) -- 获取日期年份 2023-06-05 -\u0026gt; 2023 EXTRACT(MONTH FROM date_value) -- 获取日期月份 2023-06-05 -\u0026gt; 6 LPAD(EXTRACT(MONTH FROM calendar.date_value), 2, '0') -- 获取日期月份(补零) 2023-06-05 -\u0026gt; 06 SUBSTR(qj.fromdate,-10, 7) -- 从日期字符串获取月字符串 2023-06-05 -\u0026gt; 2023-06 附件泛微考勤表 E-R 图 oracle 结合泛微 OA 实现考勤统计 计算方法 假期类型，1 节假日当天、3 节假日假期、2 节假日补调上班日期\n根据算法的不同来确认：\n星期 type D 五天制 六天制(周六) 周一 null 1 0 0 周二 null 2 0 0 周三 null 3 0 0 周四 3 4 -1 -1 周五 3 5 -1 -1 周六 1 6 0 -1 周天 2 7 +1 +1 汇总 \u0026#xa0; \u0026#xa0; 5-2+1=4 6-3+1=4 总结：使用不同的计算策略（五天班、六天班）计算公式如下\n$$\\mbox{应出勤天数} = \\mbox{基础出勤天数} - \\mbox{出勤天内假期} + \\mbox{出勤天外工作日}$$\nsql 实现 实现了包括工作日+考勤组节假日的应出勤天数\n大致思路，首先生成日历表，再关联假期表，分别统计出基础出勤天数、出勤天内假期、出勤天外工作日\nselect calendar.fmonth, ho.groupid, fmonthday5 - NVL(subday5,0) + NVL(addday5,0) as fmonthday5, fmonthday6 - NVL(subday6,0) + NVL(addday6,0) as fmonthday6 FROM (SELECT EXTRACT(YEAR FROM calendar.date_value) || '-' || LPAD(EXTRACT(MONTH FROM calendar.date_value), 2, '0') fmonth, SUM(CASE WHEN TO_CHAR(date_value, 'D') \u0026lt; 6 THEN 1 ELSE 0 END) fmonthday5, SUM(CASE WHEN TO_CHAR(date_value, 'D') \u0026lt; 7 THEN 1 ELSE 0 END) fmonthday6 FROM (select TRUNC(TO_DATE('2023', 'YYYY'), 'YYYY') + LEVEL - 1 AS date_value FROM dual CONNECT BY LEVEL \u0026lt;= 365) calendar GROUP BY EXTRACT(YEAR FROM date_value) , EXTRACT(MONTH FROM date_value) ) calendar LEFT JOIN (select ho.groupid, EXTRACT(YEAR FROM TO_DATE(ho.holidaydate,'yyyy-mm-dd')) || '-' || LPAD(EXTRACT(MONTH FROM TO_DATE(ho.holidaydate,'yyyy-mm-dd')), 2, '0') fmonth, SUM(CASE WHEN TO_CHAR(TO_DATE(ho.holidaydate,'yyyy-mm-dd'), 'D') \u0026lt; 6 AND ho.changetype in(1,3) THEN 1 ELSE 0 END) subday5, SUM(CASE WHEN TO_CHAR(TO_DATE(ho.holidaydate,'yyyy-mm-dd'), 'D') \u0026gt; 5 AND ho.changetype=2 THEN 1 ELSE 0 END) addday5, SUM(CASE WHEN TO_CHAR(TO_DATE(ho.holidaydate,'yyyy-mm-dd'), 'D') \u0026lt; 7 AND ho.changetype in(1,3) THEN 1 ELSE 0 END) subday6, SUM(CASE WHEN TO_CHAR(TO_DATE(ho.holidaydate,'yyyy-mm-dd'), 'D') \u0026gt; 6 AND ho.changetype=2 THEN 1 ELSE 0 END) addday6 FROM KQ_HOLIDAYSET ho GROUP BY ho.groupid, EXTRACT(YEAR FROM TO_DATE(ho.holidaydate,'yyyy-mm-dd')), EXTRACT(MONTH FROM TO_DATE(ho.holidaydate,'yyyy-mm-dd')) ) ho -- 假期月汇总表, 当月有节假日 ON calendar.fmonth = ho.fmonth and ho.groupid is null; ( SELECT EXTRACT(YEAR FROM calendar.date_value) || '-' || LPAD(EXTRACT(MONTH FROM calendar.date_value), 2, '0') fnomalmonth, SUM(CASE WHEN TO_CHAR(date_value, 'D') \u0026lt; 6 THEN 1 ELSE 0 END) fmonthnomalday5, SUM(CASE WHEN TO_CHAR(date_value, 'D') \u0026lt; 7 THEN 1 ELSE 0 END) fmonthnomalday6 FROM (select TRUNC(TO_DATE('2023', 'YYYY'), 'YYYY') + LEVEL - 1 AS date_value FROM dual CONNECT BY LEVEL \u0026lt;= 365) calendar GROUP BY EXTRACT(YEAR FROM date_value) , EXTRACT(MONTH FROM date_value) ) normalworkday; -- 正常工作日表，当月无节假日 ","permalink":"/posts/%E6%B3%9B%E5%BE%AEoa-%E8%AE%A1%E7%AE%97%E5%91%98%E5%B7%A5%E6%AF%8F%E6%9C%88%E5%BA%94%E5%87%BA%E5%8B%A4%E5%A4%A9%E6%95%B0/","series":[],"tags":[],"title":"泛微OA 计算员工每月应出勤天数"},{"authors":[],"categories":[],"content":"Mybatis Config 雪花算法id，用 redis 自动管理 workerId。\n本章代码直接提供了使用 mybatis 配置雪花算法 id，并且利用 redis 自动注册 workerId；\n另外提供了一个方法，让 springboot 在启动好之前就初始化好数据库连接池；\n@Slf4j @Configuration @EnableTransactionManagement public class MybatisPlusConfig { private final String idWorker = \u0026quot;WorkerId\u0026quot;; @Value(\u0026quot;${spring.application.name}\u0026quot;) private String serviceName; @Resource private RedisTemplate\u0026lt;String,Long\u0026gt; redisTemplate; private final String script = \u0026quot;local now = redis.call('TIME')[1]\\n\u0026quot; + \u0026quot;local idWordsKey = KEYS[1]\\n\u0026quot; + \u0026quot;local sp = ':'\\n\u0026quot; + \u0026quot;for i = 0, 1023 do\\n\u0026quot; + \u0026quot; local serviceKey = idWordsKey..sp..i\\n\u0026quot; + \u0026quot; if redis.call('SETNX', serviceKey, now) == 1 then\\n\u0026quot; + \u0026quot; redis.call('Expire', serviceKey, 30)\\n\u0026quot; + \u0026quot; return i;\\n\u0026quot; + \u0026quot; end\\n\u0026quot; + \u0026quot;end\\n\u0026quot; + \u0026quot;return -1\u0026quot;; /** * 分页插件 */ @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); return interceptor; } @Bean public IdentifierGenerator idGenerator() { if (serviceName == null || serviceName.length() == 0){ log.error(\u0026quot;雪花算法初始化失败，【 app.idKey 】配置为空。\u0026quot;); return null; } long num = getWorkerIdNum(); // 获取前 5 位 long dataCenterId = num \u0026gt;\u0026gt; 5; // 获 取 后 5 位 long workerId = num \u0026amp; (~(-1L \u0026lt;\u0026lt; 5L)); // 自定义初始化雪花算法 log.info(\u0026quot;==== [Init Snowflake suceessfully]: dataCenterId:{},workerId:{}\u0026quot;, dataCenterId, workerId); return new DefaultIdentifierGenerator(workerId, dataCenterId); } /** * 获取机器标识号 * param serviceName 服务名称,不再需要,r edis 框架自动添加服务名 */ private Long getWorkerIdNum() { // 实例化脚本对象 DefaultRedisScript\u0026lt;Long\u0026gt; lua = new DefaultRedisScript\u0026lt;\u0026gt;(); lua.setResultType(Long.class); lua.setScriptText(script); List\u0026lt;String\u0026gt; keys = new ArrayList\u0026lt;\u0026gt;(2); keys.add(idWorker); // 获取序列号 Long num = redisTemplate.execute(lua, keys, keys.size()); String targetKey = String.join(\u0026quot;:\u0026quot;, keys) + \u0026quot;:\u0026quot; + num; // -1 代表机器用完了，重试 if (num \u0026lt; 0){ log.erro r( \u0026quot;目前 Id 已用完，请重新启动试试\u0026quot;); System.exit(0); } // 自动续期 this.autoExpire(targetKey); return num; } /** * 自动续期 */ private void autoExpire(String key) { ScheduledExecutorService executorService = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern(\u0026quot;id_auto_expire-%d\u0026quot;).daemon(true).build()); executorService.scheduleAtFixedRate(() -\u0026gt; { redisTemplate.expire(key, 30, TimeUnit.SECONDS); log.debu g( \u0026quot;自动续期 id 成功:{}\u0026quot;, key); }, 0, 10, TimeUnit.SECONDS); } public String getServiceName() { return serviceName; } public void setServiceName(String serviceName) { this.serviceName = serviceName; } /** * init connection when springboot startup */ @Bean public ApplicationRunner connectionInit(DataSource dataSource) { return args -\u0026gt; { dataSource.getConnection(); log.info(\u0026quot;==== [datasource connection inited]\u0026quot;); }; } ","permalink":"/posts/mybatis-config/","series":[],"tags":["Java"],"title":"Mybatis Config 雪花算法id，用 redis 管理 workerId"},{"authors":[],"categories":[],"content":"springcloud 整合 shardingsphere 及 seata, 为分布式事务的场景提供了十分优雅的解决方案\n垂直 vs 水平 拆分 垂直分库，把单一数据库按业务进行划分，做到专库专表\n垂直分表，把表中的一部分数据列存储到一张表，再将另外一部分数据列存储到另外一张或多张表，这种方式叫垂直分表\n垂直分，都是切分表头，更多考虑微服务划分和数据库设计。\n水平分库，表的数据一部分存储在一个数据库，另一部分数据存储在另外一个数据库中\n水平分表，表的数据一部分存储在一个表，另一部分数据存储在另外一个表中\n水平分，都是切表体\n分库分表带来的问题：\n跨节点连接查询问题，分页、排序 多数据源管理问题， springcloud 整合 shardingsphere 及 seata 依赖 依赖我们选择引入、spring-cloud-starter-alibaba-seata 作为 seata 的起步依赖、sharding-jdbc-spring-boot-starter 作为 shardingshpere 分库分表的核心依赖、sharding-transaction-base-seata-at 作为 shardingsphere 支持 seata-at 模式的依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-seata\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${depend on you springcloud version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shardingsphere\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sharding-jdbc-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shardingsphere\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sharding-transaction-base-seata-at\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 数据库环境 模拟分库（最常见的方案），模拟将数据分库存储至 2 个不同的库，首先创建好 2 个数据库 cube_ld_archetype_dev_1、cube_ld_archetype_dev_1，并且创建相同的表 t_ld_daily_user_d。\ndelimiter ; CREATE TABLE cube_ld_archetype_dev_1.t_ld_daily_user_d ( `id` bigint NOT NULL, `name` varchar(16) NOT NULL COMMENT '姓名', `dd_union_id` varchar(32) DEFAULT NULL COMMENT '钉钉 id', `gender` tinyint NOT NULL COMMENT '性别，1 男 2 女', `mobile` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci DEFAULT NULL, `phone` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci DEFAULT NULL, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', `update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间', `modifier` bigint NOT NULL DEFAULT '-1' COMMENT '修改人', `creator` bigint NOT NULL DEFAULT '-1' COMMENT '创建人', `tenant_id` bigint NOT NULL DEFAULT '-1' COMMENT '租户', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb3 COMMENT='用户表'; CREATE TABLE cube_ld_archetype_dev_2.t_ld_daily_user_d ( `id` bigint NOT NULL, `name` varchar(16) NOT NULL COMMENT '姓名', `dd_union_id` varchar(32) DEFAULT NULL COMMENT '钉 钉 id', `gender` tinyint NOT NULL COMMENT '性别，1 男 2 女', `mobile` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci DEFAULT NULL, `phone` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci DEFAULT NULL, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', `update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间', `modifier` bigint NOT NULL DEFAULT '-1' COMMENT '修改人', `creator` bigint NOT NULL DEFAULT '-1' COMMENT '创建人', `tenant_id` bigint NOT NULL DEFAULT '-1' COMMENT '租户', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb3 COMMENT='用户表'; 由于使用了 seata 的 at 模式，因此需要在每个库创建 undo_log 表\ndelimiter ; CREATE TABLE IF NOT EXISTS cube_ld_archetype_dev_1.`undo_log` ( `branch_id` BIGINT NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(128) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8mb4 COMMENT ='AT transaction mode undo table'; ALTER TABLE cube_ld_archetype_dev_1.`undo_log` ADD INDEX `ix_log_created` (`log_created`); CREATE TABLE IF NOT EXISTS cube_ld_archetype_dev_2.`undo_log` ( `branch_id` BIGINT NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(128) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8mb4 COMMENT ='AT transaction mode undo table'; ALTER TABLE cube_ld_archetype_dev_2.`undo_log` ADD INDEX `ix_log_created` (`log_created`); 编写配置 由于使用了 springcloud-seata 和 springcloud-shardingsphere 的依赖，因此可以直接在注册中心上进行配置;\n可以使用 2 个配置文件来进行 seata 和 shardingsphere 分开配置；\nsharingsphere 配置使用 tenant_id 来进行分库；\nseata 配置, 此配置可在 nacos 配置中心完成\nseata: config: type: nacos nacos: server-addr: ${spring.cloud.nacos.config.server-addr} group: SEATA_GROUP namespace: ${spring.cloud.nacos.config.namespace} username: ${nacos.username} password: ${nacos.password} cluster: default data-id: seataServer.properties registry: type: nacos nacos: server-addr: ${spring.cloud.nacos.discovery.server-addr} group: SEATA_GROUP namespace: ${spring.cloud.nacos.discovery.namespace} username: ${nacos.username} password: ${nacos.password} application: seata-server cluster: default tx-service-group: default_tx_group service: vgroup-mapping: default_tx_group: default enable-auto-data-source-proxy: true data-source-proxy-mode: AT shardingsphere 配置，此配置可在 nacos 配置中心完成\nspring: jackson: time-zone: Asia/Shanghai cache: type: none shardingsphere: dataSource: names: ds1,ds2 ds1: type: com.zaxxer.hikari.HikariDataSource driverClassName: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://dsip1:3306/cube_ld_archetype_dev_1?useUnicode=true\u0026amp;characterEncoding=UTF-8\u0026amp; serverTimezone=Asia/Shanghai\u0026amp;zeroDateTimeBehavior=convertToNull\u0026amp; autoReconnect=true\u0026amp;failOverReadOnly=false\u0026amp;maxReconnects=2\u0026amp;useSSL=false username: root password: xxx ds2: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://dsip2:3306/cube_ld_archetype_dev_2?useUnicode=true\u0026amp;characterEncoding=UTF-8\u0026amp; serverTimezone=Asia/Shanghai\u0026amp;zeroDateTimeBehavior=convertToNull\u0026amp; autoReconnect=true\u0026amp;failOverReadOnly=false\u0026amp;maxReconnects=2\u0026amp;useSSL=false username: root password: xxx sharding: tables: t_ld_daily_user_d: database-strategy: inline: sharding-column: tenant_id algorithm-expression: ds$-\u0026gt;{tenant_id % 2 + 1} seata.conf 这一步是 shardingsphere 与 seata 整合的配置，此配置需要在项目的 resource 目录下，目前不是很优雅，但是要实现在 nacos 上配置也不难。\nsharding.transaction.seata.at.enable=true client.application.id=archetype client.transaction.service.group=default_tx_group 编写代码 注意：@Transactional 和 @ShardingTransactionType 注解必须同时添加才能使分布式事务生效 TransactionType.BASE 其实就是 shardingsphere 对于弱一致性事务的定义，在这里可理解 TransactionType.BASE 是 seata at 事务的映射。 当然除了弱一致性以外，还有强一致性 XA 事务，seata 默认也是支持的，只是 XA 事务依赖数据库支持，在使用 XA 事务时你需要提前确认数据库是否支持 XA 事务。\n在下面的代码中，程序有一个除零错误，故意设计一个错误，我们期望分布式事务生效的情况下，能回滚 userMapper.insert(user1) 这行代码对数据库的操作。\n/** * save mutiple record * testing distributed transaction */ @PostMapping(\u0026quot;/saveTestShardingSphere\u0026quot;) @Transactional(rollbackFor = Exception.class) @ShardingTransactionType(TransactionType.BASE) public Result\u0026lt;Long\u0026gt; saveTestShardingSphere() { User user1 = new User(); user1.setId(1L); user1.setTenantId(1L); user1.setName(\u0026quot;van1\u0026quot;); user1.setGender(true); user1.setPhone(\u0026quot;7789\u0026quot;); user1.setDdUnionId(\u0026quot;7789\u0026quot;); userMapper.insert(user1); User user2 = new User(); user2.setId(2L); user2.setTenantId(2L); user2.setName(\u0026quot;van2\u0026quot;); user2.setGender(true); user2.setPhone(\u0026quot;7789\u0026quot;); user2.setDdUnionId(\u0026quot;7789\u0026quot;); userMapper.insert(user2); int errorInt = 1 / 0; return Result.success(); } 启动 seata-server seata 的 AT 事务要求 TC 与 RM 能双向通讯，因此在做测试的时候，常常需要在本地启动一个 seata-server（TC）以确保事务生效。\ncd $seata-server-home/bin sh seata-server.sh -p 8091 -h 172.20.10.2 -m file tail -f ../logs/start.out 启动 springcloud 项目 mvn clean -T 1C install -f ../pom.xml -Dmaven.test.skrp=true -U java \\ -Xms1024m -Xmx1024m \\ -Dspring.application.name=archetype \\ -Dspring.cloud.nacos.config.file-extension=yml \\ -Duser.timezone=GMT+08 \\ -Dserver.port=8080 \\ -Dspring.cloud.nacos.discovery.server-addr=nacos:8848 \\ -Dspring.cloud.nacos.discovery.namespace=e29572d7-7ccc-4a18-81da-dbe891677336 \\ -Dspring.cloud.nacos.config.server-addr=nacos:8848 \\ -Dspring.cloud.nacos.config.namespace=e29572d7-7ccc-4a18-81da-dbe891677336 \\ -Dspring.config.import[0]=nacos:seata-at \\ -Dspring.config.import[1]=nacos:archetype-shardingjdbcDb \\ -Dspring.cloud.nacos.discovery.register-enabled=true \\ -Dlogging.level.com.baomidou.mybatisplus=DEBUG \\ -Dmybatis-plus.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl \\ -jar ./target/archetype.jar 接口测试 发起请求测试\nPOST http://localhost:8080/user/saveTestShardingSphere 数据库查看\ndelimiter ; -- delete from cube_ld_archetype_dev_1.t_ld_daily_user_d; -- delete from cube_ld_archetype_dev_2.t_ld_daily_user_d; SELECT * FROM cube_ld_archetype_dev_1.t_ld_daily_user_d; SELECT * FROM cube_ld_archetype_dev_2.t_ld_daily_user_d; 日志\nBranch Rollbacked result: PhaseTwo_Rollbacked 总结 shardingsphere 与 seata 的整合的确做到了配置清晰，使用简单；\n强强联合，为分布式事务的场景提供了十分优雅的解决方案；\n","permalink":"/posts/seata-shardingsphere1/","series":[],"tags":["Java"],"title":"springcloud 整合 shardingsphere 及 seata"},{"authors":[],"categories":[],"content":"如何排查：java.lang.OutOfMemoryError: unable to create native thread\njava.lang.OutOfMemoryError: unable to create native thread 测试代码 for (int i = 0; i \u0026lt; 3500; i++) { new Thread(() -\u0026gt; { try { try {Thread.sleep(5000L);} catch (InterruptedException e) {e.printStackTrace();} TimeUnit.HOURS.sleep(1); log.info(\u0026quot;\\n==== [log]: {} {}\u0026quot;, \u0026quot;sleep over\u0026quot;,Thread.currentThread().getName()); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); } 相关指令 查看进程的线程数量\njstack -l PID | grep 'java.lang.Thread.State' | wc -l jstack -l PID | grep 'java.lang.Thread.State: RUNNABLE' | wc -l jstack -l PID | grep 'java.lang.Thread.State: TIMED_WAITING' | wc -l jstack -l PID | grep 'java.lang.Thread.State: WAITING' | wc -l jstack -l PID | grep 'java.lang.Thread.State:BLOCKED' | wc -l jstack -l PID | grep 'Java-level deadlock' | wc -l 查看进程的线程状态\njstack -l PID | grep 'java.lang.Thread.State' 查看进程的线程信息\njstack -l PID 返回信息，可以看到阻塞的代码信息\n\u0026quot;Thread-4050\u0026quot; #4136 prio=5 os_prio=31 cpu=1.00ms elapsed=546.19s tid=0x0000000130247000 nid=0x354103 waiting on condition [0x00000004b9a2e000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(java.base@11.0.13/Native Method) at java.lang.Thread.sleep(java.base@11.0.13/Thread.java:334) at java.util.concurrent.TimeUnit.sleep(java.base@11.0.13/TimeUnit.java:446) at com....controller.CommentsController$$M$_jr_0E50A6F6C7FE22B0_1 .lambda$0(CommentsController.java:129) at com....controller.CommentsController$$Lambda$964$$M$_jr_0E50A6F6C7FE22B0_1 /0x0000000800e11c40.run(Unknown Source) at java.lang.Thread.run(java.base@11.0.13/Thread.java:829) ","permalink":"/posts/java-oom/","series":[],"tags":["Java"],"title":"java 栈溢出问题排查"},{"authors":[],"categories":[],"content":"RocketMQ主要由 Producer、Broker、Consumer 三部分组成，其中Producer 负责生产消息，Consumer 负责消费消息，Broker 负责存储消息。\n简介 项目地址：https://github.com/apache/rocketmq/tree/master\nRocketMQ主要由 Producer、Broker、Consumer 三部分组成，其中Producer 负责生产消息，Consumer 负责消费消息，Broker 负责存储消息。Broker 在实际部署过程中对应一台服务器，每个 Broker 可以存储多个Topic的消息，每个Topic的消息也可以分片存储于不同的 Broker。Message Queue 用于存储消息的物理地址，每个Topic中的消息地址存储于多个 Message Queue 中。ConsumerGroup 由多个Consumer 实例构成。\n消息的发布是指某个生产者向某个topic发送消息；消息的订阅是指某个消费者关注了某个topic中带有某些tag的消息，进而从该topic消费数据。\n架构 NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。\nBroker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。 注意：当前RocketMQ版本在部署架构上支持一Master多Slave，但只有BrokerId=1的从服务器才会参与消息的读负载。\nProducer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic 服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。\nConsumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，消费者在向Master拉取消息时，Master服务器会根据拉取偏移量与最大偏移量的距离（判断是否读老消息，产生读I/O），以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取。\nRocketMQ架构上主要分为四部分，如上图所示:\nProducer：消息发布的角色，支持分布式集群方式部署。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。\nConsumer：消息消费的角色，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。\nNameServer：NameServer是一个非常简单的Topic路由注册中心，其角色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。主要包括两个功能：Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活；路由信息管理，每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。然后Producer和Conumser通过NameServer就可以知道整个Broker集群的路由信息，从而进行消息的投递和消费。NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker是向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer和Consumer仍然可以动态感知Broker的路由的信息。\nBrokerServer：Broker主要负责消息的存储、投递和查询以及服务高可用保证，为了实现这些功能，Broker包含了以下几个重要子模块。\nRemoting Module：整个Broker的实体，负责处理来自Client端的请求。 Client Manager：负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息。 Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能。 HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。 Index Service：根据特定的Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询。 部署 结合部署架构图，描述集群工作流程：\n启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。 Broker启动，跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。 收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。 Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic存在哪些Broker上，轮询从队列列表中选择一个队列，然后与队列所在的Broker建立长连接从而向Broker发消息。 Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。 单节点部署 设置环境变量 1 set -x ROCKETMQ_HOME /Users/van/soft/rocketMQ 下载项目至ROCKETMQ_HOME文件目录，\nhttps://github.com/apache/rocketmq/tree/master\n下载项目至ROCKETMQ_HOME文件目录，\nhttps://github.com/apache/rocketmq-dashboard\n启动NameServer 1 nohup sh $ROCKETMQ_HOME/rocketmq-4.9.3/bin/mqnamesrv \u0026amp; 2 tail -f ~/logs/rocketmqlogs/namesrv.log 3 jps 启动borkerServer 1 nohup sh $ROCKETMQ_HOME/rocketmq-4.9.3/bin/mqbroker -n localhost:9876 \u0026amp; 2 tail -f ~/logs/rocketmqlogs/broker.log 3 jps 启动管理端 项目地址：https://github.com/apache/rocketmq-dashboard\n修改nameserver地址，application.yml\n1 ... 2 namesrvAddrs: 3 - 127.0.0.1:9876 4 ... 启动命令\nmvn springboot:run 访问地址：http://localhost:8080/#/topic\n消息发送和消费测试 1 #bash 2 export NAMESRV_ADDR=localhost:9876 3 #fish 4 set -x NAMESRV_ADDR localhost:9876 5 sh $ROCKETMQ_HOME/rocketmq-4.9.3/bin/tools.sh org.apache.rocketmq.example.quickstart.Producer 6 sh $ROCKETMQ_HOME/rocketmq-4.9.3/bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 复制和刷盘策略 复制策略：同步复制、异步复制，broker master与 slaver 之间数据同步策略\n刷盘策略：同步刷盘、异步刷盘，异步刷盘一般是将数据存储至pageCache,达到一定数量时自动进行落盘\nblocker 集群模式 单Master 只有一个blocker，只能在测试时使用，有单点故障\n多Master broker仅由多个master构成，不存在slaver。同一个topic的各个queue会平均分布至多个master节点。\n优点：配置简单、单个master宕机对集群没影响。前提是需要配置磁盘阵列。raid磁盘阵列的效率要高于master-slaver集群，raid是硬件支持，成本较高。\n缺点：未恢复之前，该机器上的消息不能被消费，消息时时性会受到影响。\n多Master多Slaver-异步复制 master与slaver之间是主备关系，即master负责消息的读写请求，而slaver仅负责消息的备份，mater宕机后的角色自动切换。\n由于是异步负责，在切换过程中可能会涉及少量消息丢失。取决于master向slaver同步数据的时机。\n多Master多Slaver-同步双写 消息写入master后，等待master将信息同步至slaver成功后，返回成功。\n优点：不存在丢失\n缺点：单个消息的RT高，导致性能要略低（约10%），master宕机后不会自动切换至slaver。\nRocketMq工作原理 消息的生产过程 Producer发送消息之前，会先向nameserver请求消息topic的路由信息 nameserver返回该topic的路由表和broker列表\n路由表：map，key为topic名称、value是一个queueData实例列表，即只要涉及到该topic的broker，一个broker对应一个queue,Queuedata中包含brokerName。简单来说，路由表的value为所有涉及该topic的brokerName\nrouterMap\u0026lt;topicName,List\u0026gt;,queueData: brokerName\nBorker列表：Map\u0026lt;brokerName、brokerDataMap\u0026gt;, brokerDataMap\u0026lt;brokerId,brokerIp\u0026gt; Producer根据消息的选择策略，从queue列表中选出一个队列，用于后续存储消息 Producer对消息做一些特殊出理，例如消息超过4M，对消息进行压缩 producer向选择出的queue所在的broker发出rpc请求，将消息发送到选择出的queue queue选择算法 轮询算法，每个queue可均匀收到消息，由于需要等到投递成功后才能进行下个节点的轮询，因此该算法存在在生产者端消息积压问题，影响消息的投递性能。 最小投递延迟算法，将消息投递至延迟最小的queue,可有效提升消息的投递性能。问题是可能出现单机过热，消息分配不均。 消息存储 数据存储在home/store目录下，该目录在启动时创建，正常关闭broker该消息会自动消失，如果启动前发现此文件存在，则说明之前是非正常关闭。 其中存储着commitlog文件，而消息是写在commitlog文件中的 config目录，存放着broker运行期间的一些配置数据 consumequeue, 存储着消费队列 index存储着消息索引文件 lock:运行期间使用到的全局资源锁 commitlog文件 偏移量 索引文件 Reblance 没次新增或者删除消费者的时候都会触发reblance，reblance会导致消息积压和消息重复消费的问题。\n另外如果消费者数量大于queue时，消息只会负载至有限的消费者，这个叫reblance的限制\n","permalink":"/posts/rocketmqintroduction/","series":[],"tags":["Java"],"title":"RocketMQ 必须知道的理论知识"},{"authors":[],"categories":[],"content":"使用 Emacs 导出 html 样式，类似于 doom emacs doc 的 css style\n样式引用：https://docs.doomemacs.org/latest/#/modules\n一个类 doom doc 的 org html 样式模版 点此预览🪄\n使用 配置 snippet 模版，然后在 org mode 文件中使用 tt tab 就可展开此模版。\n# -*- mode: snippet -*- # name: title # key: tt # -- #+title: `(file-name-sans-extension (buffer-name))` #+SUBTITLE: this is subtitle #+AUTHOR: autor #+HTML_HEAD: \u0026lt;script src=\u0026quot;scroll.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; #+HTML_HEAD: \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; type=\u0026quot;text/css\u0026quot; href=\u0026quot;org_css.css\u0026quot;/\u0026gt; #+HTML_HEAD: \u0026lt;script src=\u0026quot;https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; #+OPTIONS: prop:nil timestamp:t \\n:t ^:nil f:t toc:t author:t num:t H:2 #+LATEX_COMPILER: xelatex #+LATEX_CLASS: elegantpaper #+MACRO: htmlred @@html:\u0026lt;font color=\u0026quot;red\u0026quot;\u0026gt;\u0026lt;/font\u0026gt;@@ #+MACRO: latexred @@latex:{\\color{red}@@@@latex:}@@ #+latex:\\newpage 想使用在线版的静态文件，可以使用下面的配置进行替换\n#+HTML_HEAD: \u0026lt;link href=\u0026quot;https://emacs-1308440781.cos.ap-chengdu.myqcloud.com/org_css.css\u0026quot; rel=\u0026quot;stylesheet\u0026quot;\u0026gt;\u0026lt;/link\u0026gt; #+HTML_HEAD: \u0026lt;script src=\u0026quot;https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; #+HTML_HEAD: \u0026lt;script src=\u0026quot;https://emacs-1308440781.cos.ap-chengdu.myqcloud.com/scroll.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; 字体样式 Table 1: 字体样式说明 粗体 bold 斜体 italic 下划线 underlined 中横线 strike-through 代码，按键 code 特殊说明 quote 摘要、引用 可使用`quote`来进行代码块补全，表示摘要，引用\nTECO - Tape [later text] Editor/COrrector\nA combination text editor/really horrible ProgrammingLanguage. To quote the paper “RealProgrammers don’t use Pascal” (1983):\nnotice 注意事项、提醒 你有许多已标记的项目并且你可能错过一个重要的项目时，提醒可以提供帮助\nPlease do not file or answer Doom Emacs issues on Reddit, Twitter, or StackOverflow. Kindly refer them to this section.\n这是 1 个例子\n段落及高亮 Example of an comment.\n原文：用友 bip 产品功能说明 ，在说明文档\n大数据中 最宝贵 、最难以代替的就是数据，一切都围绕数据。\nHDFS 是最早的大数据存储系统，存储着宝贵的数据资产，各种新算法、框架要想得到广泛使用，必须支持 HDFS，才能获取已存储在里面的数据。所以大数据技术越发展，新技术越多，HDFS 得到的支持越多，越离不开 HDFS。HDFS 也许不是最好的大数据存储技术，但依然是最重要的大数据存储技术。\nHDFS 是如何实现大数据高速、可靠的存储和访问的呢？\nHadoop 分布式文件系统 HDFS 的设计目标是管理数以千计的服务器、数以万计的磁盘，将大规模的服务器计算资源当作一个单一存储系统进行管理，对应用程序提供数以 PB 计的存储容量，让应用程序像使用普通文件系统一样存储大规模的文件数据。 表格 C-c ~ to convert to tabel.el table\nC-c ~ to convert to org table\norg table M-h M-l for move Columns left and right\norg table M-k M-j for move Rows up and down\n# table.el for merge Columns or Rows Table 2: square N N^2 N^3 N^4 sqrt(n) sqrt[4](N) 1 1 1 1 1 1 2 4 8 16 1.4142136 1.1892071 3 9 27 81 1.7320508 1.3160740 Table 3: student Student Prob 1 Prob 2 Prob 3 Total Note Maximum 10 15 25 50 10.0 Peter 10 8 23 41 8.2 Sam 2 4 3 9 1.8 Average \u0026#xa0; \u0026#xa0; \u0026#xa0; 25.0 \u0026#xa0; Table 4: long table Format Fine-grained-control Initial Effort Syntax simplicity Editor Support Integrations Ease-of-referencing Versatility Word Word^2 Word^3 Word^4 sqrt(Word) sqrt(sqrt(Word)) 2 2 LaTeX LaTeX^2 LaTeX^3 LaTeX^4 sqrt(LaTeX) sqrt(sqrt(LaTeX)) 4 3 Org Mode Org^2 Mode^2 Org^3 Mode^3 Org^4 Mode^4 sqrt(Org Mode) sqrt(sqrt(Org Mode)) 4 4 Markdown Markdown^2 Markdown^3 Markdown^4 sqrt(Markdown) sqrt(sqrt(Markdown)) 3 1 Markdown + Pandoc (Markdown + Pandoc)^2 (Markdown + Pandoc)^3 (Markdown + Pandoc)^4 sqrt(Markdown + Pandoc) sqrt(sqrt(Markdown + Pandoc)) 3 2 awk 表格 aardvark 555-5553 1200/300 B alpo-net 555-3412 2400/1200/300 A barfly 555-7685 1200/300 A bites 555-1675 2400/1200/300 A camelot 555-0542 300 C core 555-2912 1200/300 C fooey 555-1234 2400/1200/300 B foot 555-6699 1200/300 B macfoo 555-6480 1200/300 A sdace 555-3430 2400/1200/300 A sabafoo 555-2127 1200/300 C /foo/ { print $0 } Table 5: 筛选出 foo 匹配的行 fooey 555-1234 2400/1200/300 B foot 555-6699 1200/300 B macfoo 555-6480 1200/300 A sabafoo 555-2127 1200/300 C 表格自增 id 0 字段名 名称 1 age 年龄 2 bir 出生年月日 #+tblfm: $1=@#-1 C-c C-c to execute it\nLaTex 公式 $\\mbox{需求的价格弹性系数} = \\frac{\\mbox{需求的变动率}}{\\mbox{价格的变动率}}$ $$\\mbox{需求的价格弹性系数} = \\frac{\\mbox{需求的变动率}}{\\mbox{价格的变动率}}$$\n$$\\begin{aligned} \\cos 3\\theta \u0026amp; = \\cos (2 \\theta + \\theta) \\ \u0026amp; = \\cos 2 \\theta \\cos \\theta - \\sin 2 \\theta \\sin \\theta \\ \u0026amp; = (2 \\cos ^2 \\theta -1) \\cos \\theta - (2 \\sin \\theta\\cos \\theta ) \\sin \\theta \\ \u0026amp; = 2 \\cos ^3 \\theta - \\cos \\theta - 2 \\sin ^2 \\theta \\cos \\theta \\ \u0026amp; = 2 \\cos ^3 \\theta - \\cos \\theta - 2 (1 - \\cos ^2 \\theta )\\cos \\theta \\ \u0026amp; = 4 \\cos ^3 \\theta -3 \\cos \\theta \\end{aligned} $$\nOrg 代码 代码片段开启行号，修改 `~/.emacs.d/.local/straight/repos/org/lisp/ox-html.el`\n(let* ((code-lines (split-string code \u0026quot;\\n\u0026quot;)) (code-length (length code-lines)) (num-fmt (and num-start (format \u0026quot;%%%ds \u0026quot; (format \u0026quot;%%%ds: \u0026quot; Java 代码 /** * @param request 调用的请求参数 * @param needLog true 需要记录日志 false 不记录日志 * @return */ protected NcApiResponse runApply(NcApiRequest request, Boolean needLog) { NcApiResponse ncApiResponse = null; try { final NcApiRequest ncApiRequest = executeBefore(request); ncApiResponse = executeGetRequest(ncApiRequest); } catch (Exception e) { afterExecute(needLog, e, request, ncApiResponse); if (e instanceof BizException) { throw new BizException(\u0026quot;NC 提示\u0026quot;, ((BizException) e).getErrorMsg(), e); } else { throw new BizException(\u0026quot;NC 异常\u0026quot;, e.getMessage()); } } return ncApiResponse; } babel java List\u0026lt;Integer\u0026gt; a = Arrays.asList(1, 2); List\u0026lt;Integer\u0026gt; a = Arrays.asList(1, 2); List\u0026lt;Integer\u0026gt; a = Arrays.asList(1, 2); List\u0026lt;Integer\u0026gt; a = Arrays.asList(1, 2); List\u0026lt;Integer\u0026gt; a = Arrays.asList(1, 2); return a; C-c C-c to execute it, but export to html will fail when the babel java result generated.\n图片 引用本地图片 引用网络图片 dot graphviz dot\ndot sk\nplantuml plantuml with style css\nplantuml 替换原生样式\nDARKO RANGE/LIGHTORANGE/DARKBLUE/LIGHTBLUE/DARKRED/LIGHTRED/DARKGREEN/LIGHTGREEN\n!define LIGHTORANGE !includeurl C4-PlantUML/juststyle.puml plant uml 系统 Contex 架构图\nplantuml 替换原生样式\nDARKORANGE/LIGHTORANGE/DARKBLUE/LIGHTBLUE/DARKRED/LIGHTRED/DARKGREEN/LIGHTGREEN\n!define LIGHTBLUE !includeurl C4-PlantUML/juststyle.puml 泳道图\nplantuml htmlstyle\norg 转 Word pandoc -o ~/Desktop/out.docx ~/.doom.d/README.org 插入时间 C-c . 插入当前时间 \u0026lt;2023-02-25 Sat\u0026gt; K lask week J next week L next day ","permalink":"/posts/orgmodecss/","series":[],"tags":["Org","Emacs"],"title":"推荐一款 org mode 导出 html 的样式"}]